---
title: "Data Screening"
author: "PAZ"
date: "06/04/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)
Sys.setlocale("LC_ALL", "English")
```

# Introduction

This Data Screenining notebook follows the GUide to STatistical Analysis in Microbial Ecology (GUSTA ME). The purpose is to inspect the variables that we'll be using to test for hypotheses later on, and check whether they follow typical assumptions made in parametric tests such as normality, freedom from heteroskedasticity (difference in variability btw. two+ variables) and outliers. 

Reference:

https://sites.google.com/site/mb3gustame/home
Buttigieg PL, Ramette A (2014) A Guide to Statistical Analysis in Microbial Ecology: a community-focused, living review of multivariate data analyses. FEMS Microbiol Ecol. 90: 543-550.

# Packages

```{r, warning=FALSE,}
library(sm)
library(vioplot)

library(dplyr)
library(tidyr)
library(reshape)
library(ggplot2)
library("ggrepel")

library("plotly")
library("cowplot")
library("gridExtra")
library("Cairo")
library("GGally")
library("scales")
```

# Lab parameters

```{r}
# Initial signature measured in tank
initialDelta = d13Co = -31.2144

# Define initial concentration (for Raleigh plots)
Co <- 8 # ug/g dry soil (based on Corn applications)
```


# Missing values

1. Missing chemical and isotope data due to machine failure or automatic sampling servicing program.

These have been considered to be Values Missing Completely at Random (MCAR) as they are associated to the end of the automatic sampler's capacity for a certain number of events where servicing was inadequate for the discharge amounts seen during a sampling week. Here the values' missingess is not related to any other value in the data set. 

2. Isotope data for both soil and water samples due to concentration value being below the limit of detection.

These values must be considered to be Missing at Random (MAR) as the missing value has no relation to the value that 'should' be there, but does depend on other variables in the data set. Thus, other variables must be taken into account for MAR data to be considered random (i.e. missing data is "conditioned by" other data in the data set). 

# Import soils 

Convert to single time observation for merging with water observation.


```{r}
# Soils
soils = read.csv2("Data/MassBalance_R.csv", 
                       na.strings=c('#DIV/0!', '', 'NA'), header = TRUE)
colnames(soils)[colnames(soils) == "ti"] <- "Date.ti"
soils$Date.ti <- as.POSIXct(strptime(soils$Date.ti, 
                                          "%Y-%m-%d %H:%M", tz="EST")) # csv typos, option 1
sum(is.na(soils$Date.ti)) == 0

initialDelta

# Get rid of imputed values to avoid unwanted bias
soils$DD13C.North <- (ifelse(!is.na(soils$comp.d13C.SD.North), soils$comp.d13C.North - (initialDelta), NA))
soils$DD13C.Talweg <- (ifelse(!is.na(soils$comp.d13C.SD.Talweg), soils$comp.d13C.Talweg - (initialDelta), NA))
soils$DD13C.South <- (ifelse(!is.na(soils$comp.d13C.SD.South), soils$comp.d13C.South - (initialDelta), NA))


dropSoil <- c("WeekSubWeek", # "Event", 
              "B.diss", "B.filt", "CumOutDiss.g", "CumOutFilt.g", "CumOutAppMass.g",  "CumOutMELsm.g", 
              "CumAppMass.g",
              "ID.N", "ID.T",  "Area.N", "Area.T", "Area.S",
              "comp.d13C.SE.North", "comp.d13C.SE.Talweg", "comp.d13C.SE.South", 
              "f.max.comp", "f.mean.comp", "f.min.comp", "ngC.SD","ngC.SE", "N_compsoil", "N_ngC")
soils <- soils[ , !(names(soils) %in% dropSoil)]

timeApps <- soils[ , c("Date.ti", "timeSinceApp", "Event")]

# Quasi-Molten SOILS
soilGroups = read.csv2("Data/WeeklySoils_Rng.csv", 
                       na.strings=c('#DIV/0!', '', 'NA'), header = TRUE)
soilGroups$Date.ti <- as.POSIXct(strptime(soilGroups$Date.ti, 
                                          "%Y-%m-%d %H:%M", tz="EST")) # csv typos, option 1
sum(is.na(soilGroups$Date.ti)) == 0

soilGroups$comp.d13C <- ifelse(is.na(soilGroups$comp.d13C.SD), NA, soilGroups$comp.d13C)
soilGroups$ngC.Label <- ifelse(soilGroups$ngC.mean < 10, "< 10 ng", "> 10 ng")

#str(soils)

soilGrApp <- merge(soilGroups, timeApps, by = "Date.ti", all = F)
soilGrApp <- soilGrApp[complete.cases(soilGrApp[ , "timeSinceApp"]),]

soilGrApp$DD13C.comp <- ifelse(is.na(soilGrApp$comp.d13C.SD), NA, soilGrApp$DD13C.comp)

cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)

pearson_r <- cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)[4]
r_label <- sprintf("r == %0.2f", pearson_r)
p_value <- cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)[3]

if (p_value < 0.0001){
  p_label <- "(p < 0.0001)"
} else if (p_value < 0.001) {
  p_label <- "(p < 0.001)"
} else if (p_value < 0.015) {
  p_label <- ("p < 0.01")
} else {
  p_label <- "Check significance"
}

soilGrApp$Source <- ifelse(soilGrApp$Transect == "T", "Valley", "Plateau")
soilGrApp$Source <- as.factor(soilGrApp$Source)

p <- ggplot(data = subset(soilGrApp, !is.na(ngC.Label)), aes(x=Conc.mug.g.dry.soil, y=DD13C.comp))+
  geom_point(aes(group = Source, size = timeSinceApp, colour = Source)) +  # , shape = ngC.Label)) +
  theme_bw() +
  labs(size="Days post appl.", colour="Source" ) + #, shape = "Mass Carbon") +
  ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  xlab(expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)}))) +
  annotate("text", x = 5, y = 6, label = as.character(r_label), parse = T, size = 3.0) +
  annotate("text", x = 5, y = 5.5, label = p_label, parse = T, size = 3.0) +
  scale_size_continuous(range = c(1, 3)) #+
  #scale_color_hue("Group") +
  #scale_fill_manual(
  #  "CI horizontal line", values=rep(1,4),
  #  guide=guide_legend(override.aes = list(colour=c("orange", "darkred"))),
  #  labels=c("CI of 95%", "CI of 99%")
  #)
  #geom_text_repel(data = subset(soilGrApp, (!is.na(ngC.Label) & Wnum > 10) ), aes(label=Wnum),
  #               arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
  #               force = 1, 
  #               point.padding = unit(1.0, 'lines'), 
  #               max.iter = 2e3,
  #               nudge_x = .2)
p
#ggsave(p, filename = "DDvsConc_soils.png", width = 8, height = 5, units = "in", scale = 1)
#ggplotly(p)
  #stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  #stat_smooth(method = "lm", formula = y~x, se=F) 
```

## Raleigh plot


$$ ln (\frac{1000 + \delta ^{13}C_0 + \Delta\delta^{13}C }{1000 + \delta^{13} C_0 }) = (\alpha - 1) \cdot ln f = \frac{\epsilon}{1000} \cdot ln f $$

$$ f = \frac{C_t}{C_0} $$

```{r}

soilGrApp$yRaleigh <- log((1000+d13Co+soilGrApp$DD13C.comp)/(1000+d13Co))
soilGrApp$xRaleigh <- log(soilGrApp$Conc.mug.g.dry.soil/Co)

# model<-lm(yRaleigh~xRaleigh, data= soilGrApp, subset=(Wnum < 12 & !is.na(ngC.Label))) 
model<-lm(yRaleigh~xRaleigh, data= soilGrApp, subset=(!is.na(ngC.Label))) 
cof <- as.numeric(coef(model)[2]*1000)
se <- summary(model)$coef[[4]]*1000
lab <- sprintf(" epsilon == %0.2f ", cof)
labSE <- sprintf("\u00B1 %0.2f ", se)
labSE2 <- sprintf("Â± %0.2f ", se)

labSE3 <- paste(" '' %+-%  ' 0.43' ")
lab1 <- paste(lab, labSE3)

summary(model)

# Compre to each transect
modelTalweg<-lm(yRaleigh~xRaleigh, data=soilGrApp, subset=(Wnum < 12 & !is.na(ngC.Label) & Transect == "T"))
eT <- coef(modelTalweg)[2]*1000

modelNorth<-lm(yRaleigh~xRaleigh, data=soilGrApp, subset=(Wnum < 12 & !is.na(ngC.Label) & Transect == "N"))
eN <- coef(modelNorth)[2]*1000

modelSouth<-lm(yRaleigh~xRaleigh, data=soilGrApp, subset=(Wnum < 12 & !is.na(ngC.Label) & Transect == "S"))
eS <- coef(modelSouth)[2]*1000

sd(c(coef(modelSouth)[2]*1000 , coef(modelNorth)[2]*1000 , coef(modelTalweg)[2]*1000))
mean(c(coef(modelSouth)[2]*1000 , coef(modelNorth)[2]*1000 , coef(modelTalweg)[2]*1000))
#modelFull<-lm(yRaleigh~xRaleigh, data=soilGroups, subset=(Wnum < 16)) 
#summary(modelFull)  

raleigh <- ggplot(data = subset(soilGrApp, ( Wnum > 0 & !is.na(ngC.Label) & !is.na(yRaleigh) )), aes(x=xRaleigh, y=yRaleigh))+
  geom_point(aes(group = Source, size = timeSinceApp, colour = Source)) +  #, shape = ngC.Label)) +
  theme_bw() +
  scale_size_continuous(range = c(1, 3)) +
  labs(size="Days post appl.", colour="Source") + #, shape = "Mass Carbon") +
  xlab("ln f") +
  ylab("ln R/Ro") +
  ylab(expression(paste("ln  ",  R / R['0'] ))) +
  stat_smooth(data= subset(soilGrApp , ( Wnum > 0 & !is.na(ngC.Label) & !is.na(yRaleigh) )) , method = "lm", formula = y~x, se=T) +
  annotate("text", x = -0.5, y = 0.005, 
           # label = as.character(expression(paste( "\u0190", " \u2030", " = ", cof))), parse = T, size = 3.0) +
           label = lab, parse = T, size = 3.0) +
  annotate("text", x = -0.33, y = 0.005, 
           label = as.character(expression(paste( "\u00B1" , 0.36))), parse = T, size = 3.0) # +
  
  #geom_text_repel(data = subset(soilGrApp, (!is.na(ngC.Label) & Wnum > 7 & Wnum < 12) ), aes(label=Wnum),
  #               arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
  #               force = 1, 
  #               point.padding = unit(1.0, 'lines'), 
  #               max.iter = 2e3,
  #               nudge_x = .2)



  
  #geom_text_repel(aes(label=Wnum),
   #             arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
    #             force = 1, 
     #            point.padding = unit(1.0, 'lines'), 
      #           max.iter = 2e3,
       #          nudge_x = .2)
raleigh
#ggsave(raleigh, filename = "lnDDvslnConc_soils.png", width = 8, height = 5, units = "in", scale = 1)
```


### Correlation Soils

```{r}
cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)
```

Import water

```{r}
waters = read.csv2("Data/WeeklyHydroContam_R.csv")
waters$ti <- as.POSIXct(strptime(waters$ti, "%Y-%m-%d %H:%M", tz="EST"))
colnames(waters)[colnames(waters) == "ti"] <- "Date.ti"
waters$Events <- factor(waters$Events, levels = unique(waters$Events))
waters$Event <- factor(waters$Event, levels = unique(waters$Event))

dropWater <- c("N.x", "N.y", 
               "Markers" , "TimeDiff", 
               "se.d13C", "MES.mg.L", "MES.sd", "MO.mg.L", "filt.se.d13C", "f.diss", "f.filt",
               "Appl.Mass.g", 
               "DissSmeto.mg", "DissSmeto.mg.SD", 
               "DissOXA.mg", "DissOXA.mg.SD", 
               "DissESA.mg", "DissESA.mg.SD",
               "FiltSmeto.mg", "DissSmeto.mg.SD", 
               "TotSMout.mg", "TotSMout.mg.SD",
               "FracDiss", "FracFilt")
waters <- waters[ , !(names(waters) %in% dropWater)]

waterCo <- max(waters$Conc.mug.L)
d13Co

waters$yRaleigh <- log((1000+d13Co+waters$DD13C.diss)/(1000+d13Co))
waters$xRaleigh <- log(waters$Conc.mug.L/waterCo)
waters$DIa <- waters$maxQ*waters$Volume.m3/waters$Duration.Hrs



waterClean <- subset(waters, Sampled == "Sampled")
waterModel<-lm(yRaleigh~xRaleigh, data= waterClean) 
summary(waterModel)
cof <- as.numeric(coef(model)[2]*1000)
se <- summary(model)$coef[[4]]*1000


waterRaleigh <- ggplot(data = subset(waterClean, (!is.na(yRaleigh) & xRaleigh > -7 & ngC.mean.diss > 5)), aes(x=xRaleigh, y=yRaleigh))+
  geom_point(aes(size = timeSinceApp)) +
  theme_bw() +
  scale_size_continuous(range = c(1, 3)) +
  labs(size="Days post appl.") +
  xlab("ln f") +
  ylab("ln R/Ro") +
  ylab(expression(paste("ln  ",  R / R['0'] ))) +
  stat_smooth(data= subset(waterClean, (!is.na(yRaleigh) & xRaleigh > -7  & ngC.mean.diss > 5)), method = "lm", formula = y~x, se=T) 

waterRaleigh
ggsave(waterRaleigh, filename = "lnDDvslnConc_water.png", width = 8, height = 5, units = "in", scale = 1)
# Date conversion correct: 
sum(is.na(waters$Date.ti)) == 0
str(waters)

ggplot(waterClean, aes(x=TotSMout.g, y=DD13C.diss))+
  geom_point(aes(group = Event, colour = Event))+
  theme_bw() + 
  theme(legend.position="top"
        # axis.title.x = element_blank(),
        ) +
  guides(col = guide_legend(nrow =  3)) + #, 
         # shape = guide_legend(nrow =  3)) +
  ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  # xlab(expression(paste("Conc. S-Meto.  ", {({mu}*g / L)}))) +
  geom_text_repel(aes(label=Events),
                 arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
                 force = 1, 
                 point.padding = unit(1.0, 'lines'), 
                 max.iter = 2e3,
                 nudge_x = .2)


cor.test(waterClean$TotSMout.g, waterClean$DD13C.diss)
```


### Correlations Waters

```{r}
cor.test(waters$Conc.mug.L, waters$diss.d13C)
#cor.test(waters$TotSMout.g, waters$diss.d13C)

#esaoxa <- waters$MELsm.g-waters$TotSMout.g
# cor.test(esaoxa, waters$diss.d13C)
```



# Merge Soil and Water data frames

## Outlet Isotope Shifts (DD)

In the same plot consider this secondary axis, where the secondary axis is a formulat of the first:

ggplot(mpg, aes(displ, hwy)) + 
  geom_point() + 
  scale_y_continuous(
    "mpg (US)", 
    sec.axis = sec_axis(~ . * 1.20, name = "mpg (UK)")
  )

Or this: https://github.com/tidyverse/ggplot2/wiki/Align-two-plots-on-a-page

```{r}
waterClean_ng <- subset(waterClean, ngC.mean.diss > 5)
WaterSoils <- merge(waterClean_ng, soils, by = "Date.ti", all = T)



str(WaterSoils)
names(WaterSoils)
keepWS <- c("Date.ti", 
            "DD13C.diss", "SD.d13C.x",
            "DD13C.filt", "filt.SD.d13C",
            "DD13C.Talweg", "comp.d13C.SD.Talweg", 
            "DD13C.South", "comp.d13C.SD.South", 
            "DD13C.North", "comp.d13C.SD.North",
            "Event.x", "BulkCatch.d13", "BulkCatch.d13.SD" 
            #"timeSinceApp.x", "Event.x", "Events"
            )
wsSmall <- WaterSoils[ , (names(WaterSoils) %in% keepWS)]

wsSmall$DD13.Bulk <- wsSmall$BulkCatch.d13-initialDelta 

names(wsSmall)
wsSmall <- wsSmall[c("Date.ti", "Event.x",
            "DD13C.diss", "SD.d13C.x",
            "DD13C.filt", "filt.SD.d13C" ,
            "DD13C.Talweg", "comp.d13C.SD.Talweg", 
            "DD13C.South", "comp.d13C.SD.South", 
            "DD13C.North", "comp.d13C.SD.North",
            "DD13.Bulk", "BulkCatch.d13.SD")]

names(wsSmall) <- c("Date", "Event",
            "diss.measure", "diss.SD",
            "filt.measure", "filt.SD",
            "Talweg.measure", "Talweg.SD", 
            "South.measure", "South.SD", 
            "North.measure", "North.SD",
            "BulkDD.measure", "BulkDD.SD"
            )
# Conventional way of melting won't work if we need SDs.
# ws <- melt(wsSmall, id=c("Date.ti", "timeSinceApp.x", "Events", "Event.x"))

# Need to rename the columns so that I can use separate and spread from the package tidyr
#names(wsSmall)[-1][seq(2, length(names(wsSmall)) - 1, 2)] <- 
#  paste0(names(wsSmall)[-1][seq(1, length(names(wsSmall)) - 1, 2)], "-SD")
#names(wsSmall)[-1][seq(1, length(names(wsSmall)) - 1, 2)] <- 
#  paste0(names(wsSmall)[-1][seq(1, length(names(wsSmall)) - 1, 2)], "-measure")

wstidier <- wsSmall %>%
  gather(measure, value, -Date, -Event) %>%
  separate(measure, into = c("Location", "temporary_var")) %>%
  spread(temporary_var, value)

wstidier$Type <- ifelse(wstidier$Location == "diss", "Dissolved", 
                  ifelse(wstidier$Location == "filt", "Sediment",
                        "Top Soil"))

wstidier$Source <- ifelse(wstidier$Location == "diss", "Outlet", 
                  ifelse(wstidier$Location == "filt", "Outlet",
                         ifelse(wstidier$Location == "South", "Plateau",
                                ifelse(wstidier$Location == "Talweg", "Valley",
                                       ifelse(wstidier$Location == "BulkDD", "Bulk",
                                       "Plateau")))))

wstidier$Source <- as.factor(wstidier$Source)
wstidier$Type <- as.factor(wstidier$Type)
wstidier$Event <- as.numeric(wstidier$Event)

# Copy all data
wstidierAll <- wstidier

levels(wstidier$Source)
levels(wstidier$Type)
wstidier$Source <- factor(wstidier$Source, levels = c("Bulk", "Plateau","Valley", "Outlet"))
wstidier$Type <- factor(wstidier$Type, levels = c("Top Soil", "Dissolved", "Sediment" ))

# Data without the Plateau
wsNoPlat <- subset(wstidierAll, Source != "Plateau")
wsNoPlat$Source <- factor(wsNoPlat$Source, levels = c("Bulk", "Valley", "Outlet"))
levels(wsNoPlat$Source)

# epsilon
epsilon_field <- cof
initialDelta

# Subset the data to values with SD < 1
wstidier = subset(wstidier, SD < 1.50)
wsNoPlat = subset(wsNoPlat, SD < 1.50)


limits_DdC <- aes(ymin=measure-SD, ymax=measure+SD, colour = Source)

wsPlot <- ggplot(data = wsNoPlat, aes(x = Date, y = measure)) + 
  geom_errorbar(limits_DdC) +
  geom_jitter(aes(shape = Type, colour = Source)) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source == "Valley" & Event > 8 )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, colour = 'green4' , alpha = 0.1, size=0.2) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source != "Outlet" & Source != "Valley" & Event < 20 )), 
              method = "lm", formula = y ~  poly(x, 2), se = F, alpha = 0.1, size=0.2) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source == "Outlet" & Event > 1 & Type == "Dissolved")), 
              method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'Outlet'), alpha = 0.2, size=0.2) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source == "Bulk")), 
              method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'Bulk'), alpha = 0.2, size=0.2) +
  theme_bw() + 
  # Applics
  annotate("text", x = as.POSIXct('2016-03-28 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-05 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-13 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-05-17 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  # Title applics
  annotate("text", x = as.POSIXct('2016-04-01 08:04:00'), y = 7.5, 
           label = as.character(expression(paste( "\u066D", " Applications"))), parse = T, size = 4.0) +
  
  scale_x_datetime(breaks = date_breaks("2 weeks"), labels = date_format("%b %d")) +
  theme(legend.position="top"
        # axis.title.x = element_blank(),
        # axis.text.x=element_text(angle = 45, hjust = 1)
        ) +
  # geom_smooth(data=subset(ws, Source != "Outlet"), method = "lm", formula = y ~ poly(x, 2)) +
  xlab("Date") + 
  #ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  scale_y_continuous(
    expression(paste({Delta~delta}^"13","C", ' (\u2030)')), 
    sec.axis = sec_axis(trans = ~ (1-((1000 + d13Co + .)/(1000+d13Co))^(1000/cof))*100 , 
                        name = "Degr (%)", breaks=c(20, 40, 60, 80, 95) )# breaks=seq(20, 120, 15))
  ) # + 
  #scale_color_manual(name= "Source", 
  #                    values = c("black", "dodgerblue", "green", "red")
  #                   ) +
  # scale_shape_manual(name= )

wsALL <- ggplot(data = wstidier, aes(x = Date, y = measure)) + 
  geom_errorbar(limits_DdC) +
  geom_jitter(aes(shape = Type, colour = Source)) +
  #stat_smooth(data=subset(wstidier,
  #                        (Source == "Valley" & Event > 8 )), 
  #            method = "lm", formula = y ~ poly(x, 2), se = F, colour = 'darkgreen' , alpha = 0.1, size=0.2) +
  #stat_smooth(data=subset(wstidier,
  #                        (Source != "Outlet" & Source != "Valley" & Event < 20 )), 
  #            method = "lm", formula = y ~  poly(x, 2), se = F, alpha = 0.1, size=0.2) +
  stat_smooth(data=subset(wstidier,
                          (Source == "Outlet" & Event > 1 & Type == "Dissolved")), 
              method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'Outlet'), alpha = 0.2, size=0.2) +
  stat_smooth(data=subset(wstidier,
                          (Source == "Bulk")), 
              method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'Bulk'), alpha = 0.2, size=0.2) +
  theme_bw() + 
  # Applics
  annotate("text", x = as.POSIXct('2016-03-28 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-05 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-13 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-05-17 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  # Title applics
  annotate("text", x = as.POSIXct('2016-04-01 08:04:00'), y = 7.5, 
           label = as.character(expression(paste( "\u066D", " Applications"))), parse = T, size = 4.0) +
  
  scale_x_datetime(breaks = date_breaks("2 weeks"), labels = date_format("%b %d")) +
  theme(legend.position="top"
        # axis.title.x = element_blank(),
        # axis.text.x=element_text(angle = 45, hjust = 1)
        ) +
  # geom_smooth(data=subset(ws, Source != "Outlet"), method = "lm", formula = y ~ poly(x, 2)) +
  xlab("Date") + 
  #ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  scale_y_continuous(
    expression(paste({Delta~delta}^"13","C", ' (\u2030)')), 
    sec.axis = sec_axis(trans = ~ (1-((1000 + d13Co + .)/(1000+d13Co))^(1000/cof))*100 , 
                        name = "Degr (%)", breaks=c(20, 40, 60, 80, 95) )# breaks=seq(20, 120, 15))
  )  + 
  scale_color_manual(name= "Source", 
                      values = c("black", "#D55E00", "darkgreen", "dodgerblue")
                     ) # +
  # scale_shape_manual(name= )

wsALL
#wsPlot
# ggsave(wsALL, filename = "WaterSoilvsTime.png", width = 8, height = 5, units = "in", scale = 1)
```


## Testing difference in $\Delta \delta$ between groups

```{r}
names(WaterSoils)
keepDDtest <- c(
  "Date.ti",
  "diss.d13C.x", # "DD13C.diss",
  "comp.d13C.North", "comp.d13C.Talweg", "comp.d13C.South" #,
  #"DD13C.North", "DD13C.Talweg", "DD13C.South"
)

wsStatTest <- WaterSoils[, colnames(WaterSoils) %in% keepDDtest]
mwsStatTest <- melt(wsStatTest, id="Date.ti")
mwsStatTest$Group1 <- ifelse(mwsStatTest$variable == "diss.d13C.x", "Outlet", "Soil")
mwsStatTest$Group2 <- ifelse(mwsStatTest$variable == "diss.d13C.x", "Outlet", 
                             ifelse(mwsStatTest$variable == "comp.d13C.Talweg", "Valley", "Plateau"))
mwsStatTest$Group3 <- ifelse(mwsStatTest$variable == "diss.d13C.x" & 
                               mwsStatTest$Date.ti > as.POSIXct('2016-05-13 12:06:00', tz = 'EST'), "Outlet(Late)",
                      ifelse(mwsStatTest$variable == "diss.d13C.x" & 
                               mwsStatTest$Date.ti <= as.POSIXct('2016-05-13 12:06:00', tz = 'EST'), "Outlet(Early)",
                      ifelse(mwsStatTest$variable == "comp.d13C.Talweg" & 
                               mwsStatTest$Date.ti > as.POSIXct('2016-05-13 12:06:00', tz = 'EST'), "Valley(Late)",
                      ifelse(mwsStatTest$variable == "comp.d13C.Talweg" & 
                               mwsStatTest$Date.ti <= as.POSIXct('2016-05-13 12:06:00', tz = 'EST'), "Valley(Early)",
                      ifelse( (mwsStatTest$variable == "comp.d13C.North" | mwsStatTest$variable == "comp.d13C.South") &
                               mwsStatTest$Date.ti <= as.POSIXct('2016-05-13 12:06:00', tz = 'EST'), "Plateau(Early)", 
                      ifelse( (mwsStatTest$variable == "comp.d13C.North" | mwsStatTest$variable == "comp.d13C.South") &
                               mwsStatTest$Date.ti > as.POSIXct('2016-05-13 12:06:00', tz = 'EST'), "Plateau(Late)", NA
                              ))))))

mwsStatTest$Group1 <- as.factor(mwsStatTest$Group1)
mwsStatTest$Group2 <- as.factor(mwsStatTest$Group2)


library(vegan)
anosim.group1 <- anosim(mwsStatTest[, 3], grouping = Group1)
```



### Loadings

```{r}
keepLoads <- c("Date.ti",
            "DissOXA.g", "DissESA.g", "DissSmeto.g", "FiltSmeto.g", 
            "Event.x", "Events")
wsLoads <- WaterSoils[ , (names(WaterSoils) %in% keepLoads)]

mw.SM <- 283.796 # g/mol
mw.MOXA <- 279.33 # g/ml
mw.MESA <- 329.1 # g/mol
wsLoads$TPsmeq.g <- 
  wsLoads$DissOXA.g * (mw.SM/mw.MOXA) +
  wsLoads$DissESA.g * (mw.SM/mw.MESA)

wsLoads <- wsLoads[ , !(names(wsLoads) %in% c("DissOXA.g", "DissESA.g"))]

loads <- melt(wsLoads, id=c("Date.ti", "Events", "Event.x"))
 
ggplot(data = loads , aes(x=Events, y=value, fill = variable))+
  theme_bw() +
  geom_bar(stat = "identity") +
  theme(# legend.position="top"
        # axis.title.x = element_blank(),
        axis.text.x=element_text(angle = 45, hjust = 1)
        )
  # geom_bar(stat = "identity", position = position_dodge())

WaterSoils$DIE <- WaterSoils$maxQ*WaterSoils$Volume.m3/WaterSoils$Duration.Hrs

keepCor <- c("maxQ", "Duration.Hrs", "AveDischarge.m3.h", "Volume.m3", "DIE",
            "DissOXA.g", "DissESA.g", "DissSmeto.g", "FiltSmeto.g" #,
            #"NH4.mM", "TIC.ppm.filt", "Cl.mM", "NO3..mM", "PO4..mM", "NPOC.ppm", 
            #"TIC.ppm.unfilt", "TOC.ppm.unfilt"
            )

corData <- WaterSoils[ , (names(WaterSoils) %in% keepCor)]

# Transform / normalize
corData.hell <- decostand(corData, "hellinger", na.rm=T, MARGIN = 2)

library(psych)
pairs.panels(corData)

library(PerformanceAnalytics)
chart.Correlation(corData.hell)


keepLoads <- c("Date.ti",
            "DissOXA.g", "DissESA.g", "DissSmeto.g", "FiltSmeto.g", 
            "Event.x", "Events")
wsLoads <- WaterSoils[ , (names(WaterSoils) %in% keepLoads)]


```

# Outliers

```{r}
# Test function
g_param = 1.5
# g_param = 2.2  #  (Hoaglin et al.,1986; Hoaglin & Iglewicz, 1987) 
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - g_param * IQR(x) | x > quantile(x, 0.75) + g_param * IQR(x))
}


```


## Soil concentrations

Correlation will be made after variable transformation. Options tested:

a) Z-scoring transformation by translation and expansion is done to create unit-free variables with means of zero and standard deviations of one. Standardised values differ from one another in units of standard deviation. The mean of each variable is subtracted from the original values and the difference divided by the variable's standard deviation and is given by:

$$ z_i = \frac{y_i - \bar{y}}{s_y} $$

Z-scoring did not change correlation results, nor outlier reduction.

b) Scaling by expansion where all values are divided by the maximum observation.

### Outliers before transformation

```{r}

# Concentrations
soilGroups %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(Conc.mug.g.dry.soil), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = Conc.mug.g.dry.soil)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)

```

### Outliers after transformation

```{r}
soilGroups <- soilGroups %>%
  group_by(Transect) %>%
  mutate(z_conc = (Conc.mug.g.dry.soil-mean(Conc.mug.g.dry.soil))/sd(Conc.mug.g.dry.soil))


soilGroups %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(z_conc), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = z_conc)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)
```

## Soil Isotopes

```{r}
# Isotopes

temp <- na.omit(soilGroups)

temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(comp.d13C), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = comp.d13C)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)


```

Looks like 7 potential outliers in concentrations and 1 for isotopes. Removing NA's for isotopes and re-computing outliers, reduces the number of outliers to 2 in concentrations and 1 for isotopes. 

```{r}
temp <- temp %>%
  group_by(Transect) %>%
  mutate(z_d13C = (comp.d13C-mean(comp.d13C))/sd(comp.d13C))

temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(z_d13C), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = z_d13C)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)

```



# Distribution of z values (same as non-transformed)

```{r}
# plot densities 
#sm.density.compare(temp$z_conc, temp$Transect, xlab=expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)})))
sm.density.compare(temp$z_conc, temp$Transect, xlab=expression(paste("Conc. S-Meto.  Z-values")))
title(main="Catchment Soil - Concentrations")
legend("topright", levels( soilGroups$Transect), fill=2+(0:nlevels(soilGroups$Transect)))
       
#vioplot(soilGroups$Conc.mug.g.dry.soil,  names = "Catchment")
#title(expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)})))
```

## Soil Isotopes

```{r}
#vioplot(na.omit(soilGroups$comp.d13C),  names = "Catchment")
#title(expression(paste({delta}^"13","C", ' (\u2030)')))
```

```{r}

temp <- na.omit(soilGroups)
sm.density.compare(temp$comp.d13C, temp$Transect, 
                   xlab=expression(paste({delta}^"13","C", ' (\u2030)')))
title(main="Catchment Soil - Isotope Distribution")
legend("topright", levels( soilGroups$Transect), fill=2+(0:nlevels(soilGroups$Transect)))
```


```{r}

```


