---
title: "Data Screening"
author: "PAZ"
date: "06/04/2017"
output: pdf_document
bibliography: library.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)
Sys.setlocale("LC_ALL", "English")
```

# Introduction

This Data Screenining notebook follows the GUide to STatistical Analysis in Microbial Ecology (GUSTA ME). The purpose is to inspect the variables that we'll be using to test for hypotheses later on, and check whether they follow typical assumptions made in parametric tests such as normality, freedom from heteroskedasticity (difference in variability btw. two+ variables) and outliers. 

Reference:

https://sites.google.com/site/mb3gustame/home
Buttigieg PL, Ramette A (2014) A Guide to Statistical Analysis in Microbial Ecology: a community-focused, living review of multivariate data analyses. FEMS Microbiol Ecol. 90: 543-550.

# Files Used

- **MassBalance_R.csv**
- **WeeklySoils_Rng.csv** 

# Files Written

- **OutletData4Lutz_R.csv** (Data to compare against Lutz 2013 article)

# Packages

```{r, warning=FALSE,}
library(sm)
library(vioplot)

library(dplyr)
library(tidyr)
library(zoo)
library(reshape)
library(ggplot2)
library("ggrepel")

library("plotly")
library("cowplot")
library("gridExtra")
library("Cairo")
library("GGally")
library("scales")

library("plotKML")

# Stats
library("vegan")
library("cluster")

# Saving a xlxs file
# library(xlsx)
```


# Missing values

1. Missing chemical and isotope data due to machine failure or automatic sampling servicing program.

These have been considered to be Values Missing Completely at Random (MCAR) as they are associated to the end of the automatic sampler's capacity for a certain number of events where servicing was inadequate for the discharge amounts seen during a sampling week. Here the values' missingess is not related to any other value in the data set. 

2. Isotope data for both soil and water samples due to concentration value being below the limit of detection.

These values must be considered to be Missing at Random (MAR) as the missing value has no relation to the value that 'should' be there, but does depend on other variables in the data set. Thus, other variables must be taken into account for MAR data to be considered random (i.e. missing data is "conditioned by" other data in the data set). 

# Lab parameters

```{r}
# Initial signature measured in tank
initialDelta = d13Co = -32.253

epsilon_mean= -2.2 # ± 0.4
epsilon_lab = epsilon_mean

# Calculated in this Book from Bulk signatures and bulk concentrations
epsilonField_max = -1.37 + 0.53 
epsilonField_min = -1.37 - 0.53  
epsilonField_mean = -1.37 # ± 0.53

# Closed system assumption applied to field for demonstration
epsilon_field = epsilonField_mean
```


# Import soils 

Convert to single time observation for merging with water observation.


```{r}
# Soils
soils = read.csv2("Data/MassBalance_R.csv", 
                       na.strings=c('#DIV/0!', '', 'NA'), header = TRUE)
names(soils)

colnames(soils)[colnames(soils) == "ti"] <- "Date.ti"
soils$Date.ti <- as.POSIXct(strptime(soils$Date.ti, 
                                          "%Y-%m-%d %H:%M", tz="EST")) # csv typos, option 1
sum(is.na(soils$Date.ti)) == 0

initialDelta

# Get rid of imputed values to avoid bias
soils$DD13C.North <- (ifelse(!is.na(soils$comp.d13C.SD.North), soils$comp.d13C.North - (initialDelta), NA))
soils$DD13C.Talweg <- (ifelse(!is.na(soils$comp.d13C.SD.Talweg), soils$comp.d13C.Talweg - (initialDelta), NA))
soils$DD13C.South <- (ifelse(!is.na(soils$comp.d13C.SD.South), soils$comp.d13C.South - (initialDelta), NA))


dropSoil <- c("WeekSubWeek", # "Event", 
              "CumOutDiss.g", "CumOutFilt.g", "CumOutAppMass.g",  "CumOutMELsm.g", 
              # "CumAppMass.g",
              # "ID.N",  
              "ID.T",  "Area.N", "Area.T", "Area.S",
              "comp.d13C.SE.North", "comp.d13C.SE.Talweg", "comp.d13C.SE.South", 
              "ngC.SD","ngC.SE", "N_compsoil" )#, "N_ngC")
soils <- soils[ , !(names(soils) %in% dropSoil)]

soilsCheck <- soils[complete.cases(soils[ , "ID.N"]),]

timeApps <- soils[ , c("Date.ti", "timeSinceApp", "timeSinceApp.NoSo", 
                        "timeSinceApp.N", "timeSinceApp.T" , "timeSinceApp.S",
                       "Event")]

```


## Soils from Book: 06, to merge with "timeApps" 

```{r}

# Quasi-Molten SOILS
soilGroups = read.csv2("Data/WeeklySoils_Rng.csv", 
                       na.strings=c('#DIV/0!', '', 'NA'), header = TRUE)
soilGroups$Date.ti <- as.POSIXct(strptime(soilGroups$Date.ti, 
                                          "%Y-%m-%d %H:%M", tz="EST")) # csv typos, option 1
sum(is.na(soilGroups$Date.ti)) == 0

soilGroups$comp.d13C <- ifelse(is.na(soilGroups$comp.d13C.SD), NA, soilGroups$comp.d13C)
# soilGroups$ngC.Label <- ifelse(soilGroups$ngC.mean < 10, "< 10 ng", "> 10 ng")

soilGroups <- subset(soilGroups, comp.d13C.SD <= 0.70)

#str(soils)

soilGrApp <- merge(soilGroups, timeApps, by = "Date.ti", all = F)
soilGrApp <- soilGrApp[complete.cases(soilGrApp[ , "timeSinceApp"]),]

soilGrApp$DD13C.comp <- ifelse(is.na(soilGrApp$comp.d13C.SD), NA, soilGrApp$DD13C.comp)
soilGrApp <- subset(soilGrApp, comp.d13C.SD <= 0.70)

cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)

pearson_r <- cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)[4]
r_label <- sprintf("Pearson~r == %0.2f", pearson_r)
p_value <- cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)[3]

if (p_value < 0.0001){
  p_label <- "(P < 0.001)"
} else if (p_value < 0.001) {
  p_label <- "(P < 0.001)"
} else if (p_value < 0.015) {
  p_label <- ("P < 0.01")
} else {
  p_label <- "Check significance"
}

soilGrApp$Source <- ifelse(soilGrApp$Transect == "T", "Valley", "Plateau")
soilGrApp$Source <- as.factor(soilGrApp$Source)

soilGrApp.N <- subset(soilGrApp, soilGrApp$Transect == "N") 
soilGrApp.T <- subset(soilGrApp, soilGrApp$Transect == "T") 
soilGrApp.S <- subset(soilGrApp, soilGrApp$Transect == "S") 

soilGrApp.N$timeSinceApp <- soilGrApp.N$timeSinceApp.N
soilGrApp.T$timeSinceApp <- soilGrApp.T$timeSinceApp.T
soilGrApp.S$timeSinceApp <- soilGrApp.S$timeSinceApp.S

dropAppDates <- c("timeSinceApp.NoSo", "timeSinceApp.N", "timeSinceApp.T", "timeSinceApp.S")
soilGrApp.N <- soilGrApp.N[ , !(names(soilGrApp.N) %in% dropAppDates)]
soilGrApp.T <- soilGrApp.T[ , !(names(soilGrApp.T) %in% dropAppDates)]
soilGrApp.S <- soilGrApp.S[ , !(names(soilGrApp.S) %in% dropAppDates)]

soilGrApp <- rbind(soilGrApp.N, soilGrApp.T)
soilGrApp <- rbind(soilGrApp, soilGrApp.S)

p <- ggplot(data = soilGrApp, aes(x=Conc.mug.g.dry.soil, y=DD13C.comp))+
  geom_errorbar(aes(ymin = DD13C.comp - comp.d13C.SD, ymax = DD13C.comp + comp.d13C.SD)) +
  geom_errorbarh(aes(xmin = Conc.mug.g.dry.soil - Conc.ComSoil.SD, xmax = Conc.mug.g.dry.soil + Conc.ComSoil.SD)) +
  stat_smooth(data = subset(soilGrApp, Conc.mug.g.dry.soil < 8), 
              aes(x=Conc.mug.g.dry.soil, y=DD13C.comp), method = "lm", formula = y ~ poly(x, 2), se=F) +
  # geom_point(aes(group = ID, size = timeSinceApp.NoSo)) + # , colour = Source)) +  # , shape = ngC.Label)) +
  geom_point(aes(group = ID, size = timeSinceApp)) +
  # theme_bw() +
  theme_minimal() +
  theme(legend.position = "top",
        text = element_text(size=17)) +
  labs(size="   Days after application", colour="Source" ) + #, shape = "Mass Carbon") +
  ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  xlab(expression(paste("S-met Soil Concentration  ", {({mu}*g / g~dry~wt.)}))) +
  annotate("text", x = 7.0, y = 4.7, label = as.character(r_label), parse = T, size = 5) +
  annotate("text", x = 7.0, y = 4.2, label = p_label, parse = T, size = 5) +
  scale_size_continuous(range = c(1, 5), breaks= c(0, 10, 20, 30, 50), limits = c(0, 50)) + 
  scale_y_continuous(breaks=c(0, 1, 2, 3 , 4 ,5) ) + 
  # scale_size_continuous(range = c(1, 5)) +
  guides(size=guide_legend(nrow=1)) +
  annotate("rect", xmin=0, xmax=8, ymin=-0.5, ymax=0.5, alpha=0.2) +
  annotate("text", x = 4, y = -0.8, label= "italic(Dilution)", parse=T, size = 4.5) +
  geom_segment(aes(x = 6, y = -1, xend = 2.5, yend = -1),
                   arrow = arrow(length = unit(1/2, 'picas'), type = "closed")) +
  annotate("text", 
           x = 4.0, y = 3.7, 
           label= "paste(\"(\", italic(Bio), \") \", italic(degradation) )", parse=T, size = 4.5, angle=332.5) +
  geom_segment(aes(x = 6, y = 2.2, xend = 2.5, yend = 4.5),
                   arrow = arrow(length = unit(1/2, 'picas'), type = "closed"))
  
  # geom_rect(aes(xmin=0, xmax=8, ymin=-0.5, ymax=0.5), colour = "grey", alpha = 0.5) + 
  #geom_hline(yintercept = 0.5, color = "dodgerblue4", linetype = "dotted") +
  #geom_hline(yintercept = 0, color = "dodgerblue3", linetype = "dotted") +
  #geom_hline(yintercept = -0.5, color = "dodgerblue3", linetype = "dotted")
  
  #scale_color_hue("Group") +
  #scale_fill_manual(
  #  "CI horizontal line", values=rep(1,4),
  #  guide=guide_legend(override.aes = list(colour=c("orange", "darkred"))),
  #  labels=c("CI of 95%", "CI of 99%")
  #)
  #geom_text_repel(data = subset(soilGrApp, (!is.na(ngC.Label) & Wnum > 10) ), aes(label=Wnum),
  #               arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
  #               force = 1, 
  #               point.padding = unit(1.0, 'lines'), 
  #               max.iter = 2e3,
  #               nudge_x = .2)
p
#ggsave(p, filename = "images/DDvsConc_soils.png", width = 8.7, height = 6, units = "cm", scale = 1)
# 
# ggsave(p, filename = "images/DDvsConc_soils_2.pdf", device = "pdf", dpi = 300,  scale = 2)

SAVE = F
PC = T
if (SAVE){
  if (PC){
    ggsave(p, 
       filename = "D:/Documents/these_pablo/WriteUp/Alteck_PNAS_LaTeX/images/DDvsConc_soils.pdf", 
       device = "pdf", dpi = 600,  scale = 1, # )# ,
       width = 8.7, height = 6)

  }
}
#ggplotly(p)
  #stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  #stat_smooth(method = "lm", formula = y~x, se=F) 
```

### Closed system field enrichment derivation (for error estimation)

```{r}
soils$yRaleigh <- log((1000+d13Co+soils$DD13.Bulk)/(1000+d13Co))
soils$xRaleigh <- log(soils$BulkCatch.Conc/soils$iniCo.Bulk)
soilModel<-lm(yRaleigh~xRaleigh, data= soils) 
summary(soilModel)

cofsoil <- as.numeric(coef(soilModel)[2]*1000)
minX <- confint(soilModel, "xRaleigh", level = 0.95)[1]*1000
maxX <- confint(soilModel, "xRaleigh", level = 0.95)[2]*1000
se <- summary(soilModel)$coef[[4]]*1000

e_label <- sprintf("epsilon == %0.3f", cofsoil)

CI95 = maxX - cofsoil

ggplot(data = subset(soils,  !is.na(yRaleigh) ), aes(x=xRaleigh, y=yRaleigh)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x, se=F) +
  annotate("text", x = -1.5, y = 0.003, label = as.character(e_label), parse = T, size = 3.5) +
  theme_bw()
```


# Import waters

## Compare mass balance, theoretical and CSIA

```{r}
waters = read.csv2("Data/WeeklyHydroContam_R.csv")
waters$ti <- as.POSIXct(strptime(waters$ti, "%Y-%m-%d %H:%M", tz="EST"))
colnames(waters)[colnames(waters) == "ti"] <- "Date.ti"
waters$Events <- factor(waters$Events, levels = unique(waters$Events))
waters$Event <- factor(waters$Event, levels = unique(waters$Event))

# Concentration ranges not being able to quantify CSIA
low4CSIA <- subset(waters, !is.na(diss.d13C))
min(low4CSIA$Conc.mug.L)

#waters$remain_maxHalf
#waters$remain_minHalf

waterCo <- max(waters$Conc.mug.L)
d13Co

waters$yRaleigh <- log((1000+d13Co+waters$DD13C.diss)/(1000+d13Co))
waters$xRaleigh <- log(waters$Conc.mug.L/waterCo)
waters$DIa <- waters$maxQ*waters$Volume.m3/waters$Duration.Hrs

# For evidence of desorption effects, Event 7-1 (May 12th) would need to show SD < 0.54 (currently at 0.63)
# Contingent on sample repeats
waterClean <- subset(waters, Sampled == "Sampled" & SD.d13C < 0.64) # | filt.SD.d13C <= 0.75 ) 

# cor.test(waterClean$TotSMout.g, waterClean$DD13C.diss)

pearson_water_r <- cor.test(waterClean$Conc.mug.L, waterClean$DD13C.diss)[4]
water_r_label <- sprintf("Pearson~r == %0.2f", pearson_water_r)
water_p_value <- cor.test(waterClean$Conc.mug.L, waterClean$DD13C.diss)[3]
water_p_label <- sprintf("p == %0.2f", water_p_value)

waterIsoConc  <- ggplot(data = subset(waterClean), aes(x=Conc.mug.L, y=DD13C.diss))+
  stat_smooth(data = subset(waterClean), 
              aes(x=Conc.mug.L, y=DD13C.diss), method = "lm", formula = y~x, se=F) +
  geom_errorbar(aes(ymin = DD13C.diss - SD.d13C, ymax = DD13C.diss + SD.d13C)) +
  geom_errorbarh(aes(xmin = Conc.mug.L - Conc.SD, xmax = Conc.mug.L + Conc.SD)) +
  geom_point(aes(size = timeSinceApp)) +
  theme_bw() +
  scale_size_continuous(range = c(1, 4)) +
  labs(size="Days post appl.") +
  theme(axis.title.y = element_blank()) +
  #scale_y_continuous(breaks=c(0, 1, 2, 3 , 4 ,5) ) + 
  scale_y_continuous(breaks=seq(1,5,1)) +
  #ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  xlab(expression(paste("S-MET Outlet Concentration ", {({mu}*g / L)}))) +
  annotate("text", x = 20, y = 2.7, label = as.character(water_r_label), parse = T, size = 3.5) +
  annotate("text", x = 20, y = 2.3, label = water_p_label, parse = T, size = 3.5)


waterIsoConc 
#ggsave(waterIsoConc , filename = "DDvsConc_water.png", width = 8, height = 5, units = "in", scale = 1)

```

## Water Rayleigh

```{r}
waterModel<-lm(yRaleigh~xRaleigh, data= waterClean) 
summary(waterModel)

minX <- confint(waterModel, "xRaleigh", level = 0.95)[1]*1000
maxX <- confint(waterModel, "xRaleigh", level = 0.95)[2]*1000

cofwater <- as.numeric(coef(waterModel)[2]*1000)
se <- summary(waterModel)$coef[[4]]*1000

CI95 = maxX - cofwater


waterRaleigh <- ggplot(data = subset(waterClean, (!is.na(yRaleigh) & xRaleigh > -7)), aes(x=xRaleigh, y=yRaleigh))+
  geom_point(aes(size = timeSinceApp)) +
  theme_bw() +
  scale_size_continuous(range = c(1, 6)) +
  labs(size="Days post appl.") +
  xlab("ln f") +
  ylab("ln R/Ro") +
  ylab(expression(paste("ln  ",  R / R['0'] ))) +
  stat_smooth(data= subset(waterClean, (!is.na(yRaleigh) & xRaleigh > -7)), method = "lm", formula = y~x, se=T) 

waterRaleigh
# ggsave(waterRaleigh, filename = "lnDDvslnConc_water.png", width = 8, height = 5, units = "in", scale = 1)
# Date conversion correct: 
sum(is.na(waters$Date.ti)) == 0
str(waters)

ggplot(waterClean, aes(x=TotSMout.g, y=DD13C.diss))+
  geom_point(aes(group = Event, colour = Event))+
  theme_bw() + 
  theme(legend.position="top"
        # axis.title.x = element_blank(),
        ) +
  guides(col = guide_legend(nrow =  3)) + #, 
         # shape = guide_legend(nrow =  3)) +
  ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  # xlab(expression(paste("Conc. S-Meto.  ", {({mu}*g / L)}))) +
  geom_text_repel(aes(label=WeekSubWeek),
                 arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
                 force = 1, 
                 point.padding = unit(1.0, 'lines'), 
                 max.iter = 2e3,
                 nudge_x = .2)
```


## Join XY waters and soils

```{r}

p_noLeg <- p + theme(legend.position = 'none')
p_Leg <- get_legend(p)
  
water_noLeg <- waterIsoConc + theme(legend.position = 'none')  
water_Leg <- get_legend(waterIsoConc)  

grid_xyConIso <- plot_grid(p_noLeg, water_noLeg, 
                    ncol =2, nrow = 1, align ="v" #,
                    #labels = c("A", "B")
                    )

xyConcIso <- ggdraw() +
  draw_plot(grid_xyConIso, x=0., y=0.1, width =  1, height = .90) + 
  #draw_plot(water_noLeg, x=0.5, y = 0.0, width = 0.4, height = 1) +
  draw_plot(p_Leg, x=0.48, y = 0.0, width = 0.1, height = 0.1) +
  draw_label("A", x= 0.47, y = .95, size = 12, fontface = "bold") +
  draw_label("B", x= 0.97, y = .95, size = 12, fontface = "bold")

xyConcIso
# ggsave(xyConcIso , filename = "images/waterSoil_DDvsConc.png", width = 8, height = 5, units = "in", scale = 1)
```



### Correlations Waters

```{r}
cor.test(waters$Conc.mug.L, waters$diss.d13C)
#cor.test(waters$TotSMout.g, waters$diss.d13C)

#esaoxa <- waters$MELsm.g-waters$TotSMout.g
# cor.test(esaoxa, waters$diss.d13C)
```



# Merge Soil and Water data frames

Objective is to plot both soils and water temporaly

## Outlet Isotope Shifts (DD)

In the same plot consider this secondary axis, where the secondary axis is a formulation of the first:

ggplot(mpg, aes(displ, hwy)) + 
  geom_point() + 
  scale_y_continuous(
    "mpg (US)", 
    sec.axis = sec_axis(~ . * 1.20, name = "mpg (UK)")
  )
  
The equation for the secondary y-axis will be:

$$B = (1 -  (\frac{1000 + \delta ^{13}C_0 + \Delta\delta^{13}C }{1000 + \delta^{13} C_0 })^{\frac{1000}{\epsilon}}  )*100 $$  

Or this: https://github.com/tidyverse/ggplot2/wiki/Align-two-plots-on-a-page

```{r}
# SD min. selection line 914 (for dissolved)
WaterSoils <- merge(waterClean, soils, by = "Date.ti", all = T)


# Choose and rearrange variables
# names(WaterSoils)
wsSmall <- WaterSoils[c("Date.ti", "WeekSubWeek", "ID.N", "Event.y", "Events",
                     "maxQ", "AveDischarge.m3.h",
                     "dryHrsIni", "dryHrsMax", "dryHrsAve", "noEventHrsIni", "noEventHrsMax", "noEventHrsAve", # Book 4
                      "CumRain.mm", "RainInt.mmhr", ## Rainfall is per subsample (See Book 3)
                      "DD13C.diss", "SD.d13C.x",
                      "DD13C.filt", "filt.SD.d13C" ,
                      "DD13C.Talweg", "comp.d13C.SD.Talweg", 
                      "DD13C.South", "comp.d13C.SD.South", 
                      "DD13C.North", "comp.d13C.SD.North",
                      "DD13.Bulk", "BulkCatch.d13.SD")]

names(wsSmall)

keepCorrTest <- c("DD13C.diss", 
                  "DD13C.Talweg", 
                  "DD13C.South",
                  "DD13C.North",
                  "DD13.Bulk")

wsTest <- wsSmall[ , (names(wsSmall) %in% keepCorrTest)]

names(wsSmall) <- c("Date", "Week", "IDSoil", "Event", "Events",
                    "Qmax", "Qmean",
                    "dryHrsIni", "dryHrsMax", "dryHrsAve", "noEventHrsIni", "noEventHrsMax", "noEventHrsAve", # Book 4
                    "CumRain", "RainInt", ## Rainfall is per subsample (See Book 3)
                    "diss.measure", "diss.SD",
                    "filt.measure", "filt.SD",
                    "Talweg.measure", "Talweg.SD", 
                    "South.measure", "South.SD", 
                    "North.measure", "North.SD",
                    "BulkDD.measure", "BulkDD.SD"
                    )

wsTest <- wsTest[7:length(wsTest$DD13C.diss) , ]
wsTest$DD13.Bulk <- na.locf(wsTest$DD13.Bulk)
wsTest$DD13C.Talweg <- na.locf(wsTest$DD13C.Talweg)
wsTest$DD13C.South <- na.locf(wsTest$DD13C.South)
wsTest$DD13C.North <- na.locf(wsTest$DD13C.North)

cor.test(wsTest$DD13.Bulk, wsTest$DD13C.diss, method = "pearson", use = "pairwise.complete.obs")
cor.test(wsTest$DD13C.Talweg, wsTest$DD13C.diss, method = "pearson", use = "pairwise.complete.obs")
cor.test(wsTest$DD13C.North, wsTest$DD13C.diss, method = "pearson", use = "pairwise.complete.obs")
cor.test(wsTest$DD13C.South, wsTest$DD13C.diss, method = "pearson", use = "pairwise.complete.obs")


# Conventional way of melting won't work if we need SDs.
# ws <- melt(wsSmall, id=c("Date.ti", "timeSinceApp.x", "Events", "Event.x"))

# Need to rename the columns so that I can use separate and spread from the package tidyr
#names(wsSmall)[-1][seq(2, length(names(wsSmall)) - 1, 2)] <- 
#  paste0(names(wsSmall)[-1][seq(1, length(names(wsSmall)) - 1, 2)], "-SD")
#names(wsSmall)[-1][seq(1, length(names(wsSmall)) - 1, 2)] <- 
#  paste0(names(wsSmall)[-1][seq(1, length(names(wsSmall)) - 1, 2)], "-measure")

wstidier <- wsSmall %>%
  gather(measure, value, -Date, -IDSoil, -Event, -Events, -Week, 
         -Qmax, -Qmean, 
         -CumRain, -RainInt,
         -dryHrsIni, -dryHrsMax, -dryHrsAve,
         -noEventHrsIni, -noEventHrsAve) %>% # Melts data frame
  separate(measure, into = c("Location", "temporary_var")) %>% # parses the sep = "." into...
  spread(temporary_var, value) 

wstidier$Type <- ifelse(wstidier$Location == "diss", "Dissolved (Outlet)", 
                  ifelse(wstidier$Location == "filt", "Sediment",
                        "Top Soil"))

wstidier$Source <- ifelse(wstidier$Location == "diss", "Outlet", 
                  ifelse(wstidier$Location == "filt", "Outlet",
                         ifelse(wstidier$Location == "South", "South",
                               ifelse(wstidier$Location == "Talweg", "Valley",
                                       ifelse(wstidier$Location == "BulkDD", "Bulk",
                                       "North"))) ))

wstidier$Source <- as.factor(wstidier$Source)
wstidier$Type <- as.factor(wstidier$Type)
wstidier$IDSoil <- as.factor(wstidier$IDSoil)
wstidier$Event <- as.numeric(wstidier$Event)

# Copy all data
wstidierAll <- wstidier

levels(wstidier$Source)
levels(wstidier$Type)
#wstidier$Source <- factor(wstidier$Source, levels = c("Bulk", "Plateau","Valley", "Outlet"))
wstidier$Source <- factor(wstidier$Source, levels = c("Bulk", "North", "Valley", "South", "Outlet"))
wstidier$Type <- factor(wstidier$Type, levels = c("Top Soil", "Dissolved (Outlet)", "Sediment" ))


# epsilon
#epsilon_field
#initialDelta

#wstidier$DegField <- (1-((1000 + d13Co + wstidier$measure)/(1000+d13Co))^(1000/epsilon_field))*100 
#wstidier$DegLab <- (1-((1000 + d13Co + wstidier$measure)/(1000+d13Co))^(1000/epsilon_lab))*100 

#wstidier$DegDiff <- (wstidier$DegField - wstidier$DegLab) 

wstidier$Location <- as.factor(wstidier$Location)
#wstidier$Week <- as.factor(wstidier$Week)

#library(dplyr)
#detach("package:plyr")
#sumary <- na.omit(wstidier) %>% 
#  group_by(Type) %>%
#  summarise(mean = mean(DegDiff))

```

## Color palette

```{r}
library(scales) 
show_col(hue_pal()(12))

# Bulk, North, Valley, South, Outlet  
# "black", "#F8766D", "#00BA38", "#DE8C00", ("#619CFF" / "#00B4F0" / "#00BFC4")
```


## Lab Enrichment plot

```{r}
# Dissolved has been selected, but not soils or filters
wstidier2 = subset(wstidier, SD <= 0.54 & Date <= as.POSIXct('2016-06-24 14:52:00', tz = "EST"))  

mindate = min(wstidier2$Date)
maxdate = max(wstidier2$Date)

pd <- position_dodge(width = 0.5)
limits_DdC <- aes(ymin=measure-SD, ymax=measure+SD, colour = Source)

wsALL_lab <- ggplot(data = wstidier2, aes(x = Date, y = measure, group = Source) )+ 
  geom_errorbar(data=subset(wstidier2, Source == 'Bulk'), limits_DdC, size=0.2) +
  geom_errorbar(data=subset(wstidier2, Source == 'South' 
                            | Source == 'North'
                            | Source == 'Valley'
                            ), limits_DdC, size=0.1) +
  geom_errorbar(data=subset(wstidier2, Source == 'Outlet'), limits_DdC) +
  geom_point(data=subset(wstidier2, (Source == 'South'
                                     | Source == 'North'
                                     | Source == 'Valley'
                                     ) 
                         # & Date > as.POSIXct('2016-05-14 08:04:00')
                         ), 
             aes(shape = Type, 
                 colour = Source)) +
  geom_point(data=subset(wstidier2, Source == 'Outlet'), aes(shape = Type, colour = Source, size = Qmean)) +
  geom_point(data=subset(wstidier2, Source == 'Bulk'), aes(shape = Type, colour = Source)) +
  
  # Water
  stat_smooth(data=subset(wstidier2,
                          (Source == "Outlet" 
                           # & Event > 1 
                           & Type == "Dissolved (Outlet)")), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = 'Outlet'), alpha = 0.2, size=0.2) +
  # North
  stat_smooth(data=subset(wstidier2,
                          (Source == "Bulk" )), #| Source == "South" )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = 'Bulk'), alpha = 0.2, size=0.2) +
  #stat_smooth(data=subset(wstidier2,
  #                        (Source == "South")), 
  #            method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'South'), alpha = 0.2, size=0.2) +
  theme_bw() + 
  
  scale_x_datetime(breaks = date_breaks("1 month"), labels = date_format("%b %d")) +
  #scale_x_datetime(breaks = date_breaks("2 weeks"), labels = date_format("%b %d")) +
  theme(text = element_text(size=17),
        legend.position="top"
        # axis.title.x = element_blank(),
        # axis.text.x=element_text(angle = 45, hjust = 1)
        ) +
  # geom_smooth(data=subset(ws, Source != "Outlet"), method = "lm", formula = y ~ poly(x, 2)) +
  xlab("Date") + 
  #ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  scale_y_continuous(
    expression(paste({Delta~delta}^"13","C", ' (\u2030)')),
    sec.axis = sec_axis(trans = ~ (1-((1000 + d13Co + .)/(1000+d13Co))^(1000/epsilon_lab))*100 , 
                        name = "Degradation (%)", 
                        #name = element_blank(), 
                        breaks=c(20, 40, 60, 70, 80, 85, 90, 95) )# breaks=seq(20, 120, 15))
  )  + 
  scale_color_manual(name= "Source", 
                     # Actual order:
                     # Bulk, North, Outlet, South, Valley
                      values = c("#DE8C00", "#F8766D", "#00BFC4", "#C77CFF", "#00BA38"
                                 # working solution:
                                 #c("black", "#F8766D", "#00BFC4", "#DE8C00", "#00BA38"
                                 #"black", "#D55E00",  "#00BFC4",  "#B79F00", "#00BA38"
                                 # Bulk, North, outlet, South, Valley
                                 #"#D55E00", "darkgreen", "dodgerblue"
                                 ),
                     breaks=c("Bulk", "North" , "Valley" ,"South",  "Outlet"),
                     labels=c("Bulk", "North" , "Valley" ,"South",  "Outlet")
                     ) +
  
  scale_size_continuous(range = c(1, 6), breaks= c(0, 50, 100, 150, 200, 300), limits = c(0, 300))+
  annotate("rect", xmin=mindate, xmax=maxdate, ymin=-0.5, ymax=0.5, alpha=0.2) 
  # scale_size_continuous(range = c(1, 3)) 

#
# Reds
# gold = "#B79F00"
# red-pink  = "#F8766D" 
# "firebrick1", 
# 'yellow', "orange1","red", 
# pink = "#F564E3" 

# Mono
# "gray35", "ghostwhite", 'gray99'

# Greens
# 'darkgreen','darkolivegreen3','darkseagreen3','darkseagreen1'
# dark green = "chartreuse4"  
# darkish freen = "#00BA38"

# Blues
# purple = "blueviolet"
# "dodgerblue", "#00BFC4" (light blue), "#619CFF" (sharp blue),
#  "deepskyblue" 

wsALL_lab
# ggplotly(wsALL_lab)
```


## Field Enrichment Plot

```{r}

mindate = as.POSIXct("2016-03-28 00:04:00" , tz = "EST") # min(wstidier2$Date)
maxdate = as.POSIXct("2016-06-27 00:01:00", tz = "EST") 
  
wsALL_field <- ggplot(data = wstidier2, aes(x = Date, y = measure, group = Source) )+ 
  # Dissolved (Outlet) trend
  stat_smooth(data=subset(wstidier2,
                          (Source == "Outlet" 
                           # & Event > 1 
                           & Type == "Dissolved (Outlet)")), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = 'Outlet'), alpha = 0.9, size=0.2) +
  # Bulk trend
  stat_smooth(data=subset(wstidier2,
                          (Source == "Bulk" )), #| Source == "South" )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = 'Bulk'), alpha = 0.9, size=0.2) +
  # Error bars
  geom_errorbar(data=subset(wstidier2, Source == 'Bulk'), limits_DdC, size=0.2) +
  geom_errorbar(data=subset(wstidier2, Source == 'South' 
                            | Source == 'North'
                            | Source == 'Valley'
                            ), limits_DdC, size=0.1) +
  geom_errorbar(data=subset(wstidier2, Source == 'Outlet'), limits_DdC) +
  # Data points
  geom_point(data=subset(wstidier2, Source == 'Bulk'), aes(shape = Type, colour = Source), size=3) +
  geom_point(data=subset(wstidier2, (Source == 'South'
                                     | Source == 'North'
                                     | Source == 'Valley'
                                     )), aes(shape = Type, colour = Source), size=2) +
  geom_point(data=subset(wstidier2, Source == 'Outlet'), aes(shape = Type, colour = Source, size = Qmean)) +
  theme_bw() + 
  # Applications
  annotate("text", x = as.POSIXct('2016-03-28 08:04:00'), y = 0, 
           label = as.character(expression(paste( "+"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-05 00:04:00'), y = 0, 
           label = as.character(expression(paste( "+"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-13 08:04:00'), y = 0, 
           label = as.character(expression(paste( "+"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-05-25 08:04:00'), y = 0, 
           label = as.character(expression(paste( "+"))), parse = T, size = 6.0) +
  # Title applics
  annotate("text", x = as.POSIXct('2016-04-05 08:04:00'), y = 4.5, 
           label = as.character(expression(paste( "+"))), parse = T, size = 6.0) +
   annotate("text", x = as.POSIXct('2016-04-12 08:04:00'), y = 4.5, 
           label = as.character(expression(paste(" Applications"))), parse = T, size = 5.0) +
  scale_x_datetime(breaks = date_breaks("2 weeks"), labels = date_format("%b %d")) +
  #scale_x_datetime(breaks = date_breaks("1 month"), labels = date_format("%b %d")) +
  theme(text = element_text(size=17),
        legend.position="top"
        # axis.title.x = element_blank()
        # axis.text.x=element_text(angle = 45, hjust = 1)
        ) +
  xlab("Date") + 
  #ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  scale_y_continuous(
    expression(paste({Delta~delta}^"13","C", ' (\u2030)')),
    sec.axis = sec_axis(trans = ~ (1-((1000 + d13Co + .)/(1000+d13Co))^(1000/epsilon_field))*100 , 
                        name = element_blank(),
                        #name = "Degradation (%)", 
                        breaks=c(20, 40, 60, 70, 80, 85, 90, 95) )# breaks=seq(20, 120, 15))
  )  + 
  scale_color_manual(name= "Source", 
                     values = c("#DE8C00", "#F8766D", "#00BFC4", "#C77CFF", "#00BA38"
                                # c("black", "#F8766D", "#00BFC4", "#DE8C00", "#00BA38" 
                                #  "black", "#D55E00",  "#00BFC4",  "#B79F00", "#00BA38"
                                 # Bulk, North, outlet, South, Valley
                                 ),
                     breaks=c("Bulk", "North" , "Valley" ,"South",  "Outlet"),
                     labels=c("Bulk", "North" , "Valley" ,"South",  "Outlet")
                    ) +
  scale_size_continuous(range = c(1, 6), breaks= c(0, 50, 100, 150, 200, 300), limits = c(0, 300)) +
  # scale_size_continuous(range = c(1, 3)) + 
  guides(col = guide_legend(order = 1,
                            #title=expression("Source"),
                            #title.vjust = -1,
                            nrow = 2, 
                            title.position = "top",
                            keyheight = 1.5
                            ), 
         shape=guide_legend(title=("Type"), 
                            order = 2,
                            nrow=2, 
                            title.position = "top", 
                            keyheight = 1.5, title.vjust = NULL, label.vjust = NULL
                            ), 
         size = guide_legend(order = 3, 
                             #title=expression("Mean Discharge"), 
                             title=expression("Mean Discharge (" ~m^3 / h~")" ), 
                             nrow=2, 
                             title.position = "top"
                             # title.vjust = .26
                             #keyheight = 0,
                             #label.vjust = 0
                              )) +
  annotate("rect", xmin=mindate, xmax=maxdate, ymin=-0.5, ymax=0.5, alpha=0.2) 

#ggplotly(wsALL_field)
wsALL_field


```



## Join all figures
```{r}
#wsALL_lab
#wsALL_field
#wsPlot
# ggsave(wsALL, filename = "WaterSoilvsTime.png", width = 8, height = 5, units = "in", scale = 1)
# ggsave(wsALL, filename = "WaterBulkvsTime.png", width = 8, height = 5, units = "in", scale = 1)

wsALL_field_noLeg <- wsALL_field + theme(legend.position='none')
wsALL_lab_noLeg <- wsALL_lab + theme(legend.position='none')
wsAll_field_Leg  <- get_legend(wsALL_field)

labely1 = expression(epsilon ["field"])
labely2 = expression(epsilon ["lab"])

label <- substitute(paste(epsilon, " = ", epsilon_f, ", Field", epsilon, " = " , epsilon_l),
                    list(epsilon_f = signif(epsilon_field, 2), epsilon_l = signif(epsilon_lab, 2) ))

label2 <- substitute(paste(epsilon ["field"] , " = ", epsilon_f, " \u00B1 ", "0.5" ,"\u2030"),
                     list(epsilon_f = signif(epsilon_field, 2)))

label3 <- substitute(paste(epsilon ["lab"] , " = ", epsilon_l, " \u00B1 ", "0.4" ,"\u2030"),
                     list(epsilon_l = signif(epsilon_lab, 3)))
# adding label via ggdraw, in the ggdraw coordinates


wsALL <- ggdraw() +
  draw_plot(wsALL_lab_noLeg, x=0, y = 0.15, width = 1, height = 0.82) + # bottom
  draw_plot(wsALL_field_noLeg, x=0, y=.15, width = 0.945, height = .82) + # top
  draw_label(label2, x= .88, y = .10, size = 15) +
  draw_label(label3, x= .88, y = .05, size = 15) +
  draw_label(labely1 , x= .90, y = .98, size = 14) +
  draw_label(labely2 , x= .95, y = .98, size = 14) +
  draw_plot(wsAll_field_Leg, x=0.2, y=0.0, width = 0.50, height = 0.15)
 
wsALL 

# ggsave(wsALL, filename = "images/WaterSoilvsTime.png", width = 8, height = 5, units = "in", scale = 1)

SAVE = T
PC = T
if (SAVE){
  if (PC) {
    # cairo and ggdraw having issues.. works fine on MAC though
    ggsave(wsALL,
           filename = "D:/Documents/these_pablo/WriteUp/Alteck_PNAS_LaTeX/images/CatchOutlet.pdf",
           device= pdf, dpi = 600,  scale = 1, # )# ,
           width = 11.4, height = 6.4)
  } else {
    ggsave(wsALL, 
     filename = "/Users/DayTightChunks/Documents/PhD/Writeups/PNAS/Alteck_PNAS_LaTeX/images/CatchOutlet.pdf", 
      device=cairo_pdf, dpi = 600,  scale = 1, # )# ,
       width = 11.4, height = 6.4)
  }
}


#install.packages("extrafont")
#library(extrafont)
```

## Encodings

```{r}
pdf('test.pdf',encoding="MacRoman")
plot.new()
text(0,labels="\u2030")
dev.off()

```




## Check Soils

```{r}
wstidier2$IDSoil <- as.character(wstidier2$IDSoil)
split <- strsplit(wstidier2$IDSoil, "-", fixed = TRUE)
wstidier2$Soil.ID <- sapply(split, "[", 3)
wstidier2$Soil.ID <- as.factor(wstidier2$Soil.ID)

ggplot(data = wstidier2, aes(x = Date, y = measure, group = Source) )+ 
  theme_bw() +
  #geom_errorbar(data=subset(wstidier2, Type == 'Top Soil'), limits_DdC, size=0.2) +
  
  #geom_errorbar(data=subset(wstidier2, Source == 'Valley' & 
  #                            Date > as.POSIXct('2016-05-14 08:04:00')), limits_DdC, size=0.2) +
  #geom_errorbar(data=subset(wstidier2, Source == 'Outlet'), limits_DdC) +
  #geom_point(data=subset(wstidier2, Source == 'Outlet'), aes(shape = Type, colour = Source, size = Qmax)) +
  geom_point(data=subset(wstidier2, Type == 'Dissolved (Outlet)'), aes(shape = Type, colour = Source, size = Qmean)) +
  geom_point(data=subset(wstidier2, Type == 'Top Soil'), aes(colour = Source)) +

  stat_smooth(data=subset(wstidier2,
                          (Source == "North" )), #| Source == "South" )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = Source), alpha = 0.2, size=0.2) +
  stat_smooth(data=subset(wstidier2,
                          (Source == "Valley" )), #| Source == "South" )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = Source), alpha = 0.2, size=0.2) +
  stat_smooth(data=subset(wstidier2,
                          (Source == "South" )), #| Source == "South" )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, aes(colour = Source), alpha = 0.2, size=0.2) +
  geom_point(data=subset(wstidier2, Source == 'Bulk'), aes(shape = Type, colour = Source)) +
  #geom_point(data=subset(wstidier2, Source == 'Valley' & 
  #                         Date > as.POSIXct('2016-05-14 08:04:00')), aes(shape = Type, colour = Source))
  #geom_text_repel(data=subset(wstidier2, Source == 'Bulk'), aes(label=Soil.ID),
  #               arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
  #               force = 1, 
  #               point.padding = unit(1.0, 'lines'), 
  #               max.iter = 2e3,
  #              nudge_x = .2) +
  #geom_text_repel(data=subset(wstidier2, Source != 'Outlet'), aes(label=Soil.ID),
  geom_text_repel(data=subset(wstidier2, Source == 'Outlet'), aes(label=Week),
                 arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
                 force = 1, 
                 point.padding = unit(1.0, 'lines'), 
                 max.iter = 2e3,
                 nudge_x = .2)

sum(wstidier2$Location == "North")  # 10
sum(wstidier2$Location == "South")  # 12
sum(wstidier2$Location == "Talweg")  # 12
sum(wstidier2$Source == "Bulk")  # 9


write.csv2(wstidier2, 
           'Data/OutletData4Lutz_R.csv', row.names = F)


```


# Soils and Water with labels (inspection)
```{r}
# Data without the Plateau
#wsNoPlat <- subset(wstidierAll, Source != "Plateau")
wsNoPlat <- subset(wstidier, SD < 4)
#wsNoPlat$Source <- factor(wsNoPlat$Source, levels = c("Bulk", "Valley", "Outlet"))
#levels(wsNoPlat$Source)

# Subset the data to values with SD < 1
#wsNoPlat2 = subset(wsNoPlat, SD < 1.50)


limits_DdC <- aes(ymin=measure-SD, ymax=measure+SD, colour = Source)

wsPlot <- ggplot(data = wsNoPlat, aes(x = Date, y = measure)) + 
  geom_errorbar(limits_DdC) +
  geom_jitter(aes(shape = Type, colour = Source)) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source == "Valley" & Event > 8 )), 
              method = "lm", formula = y ~ poly(x, 2), se = F, colour = 'green4' , alpha = 0.1, size=0.2) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source != "Outlet" & Source != "Valley" & Event < 20 )), 
              method = "lm", formula = y ~  poly(x, 2), se = F, alpha = 0.1, size=0.2) +
  stat_smooth(data=subset(wsNoPlat,
                          (Source == "Outlet" & Event > 1 & Type == "Dissolved (Outlet)")), 
              method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'Outlet'), alpha = 0.2, size=0.2) +
  #stat_smooth(data=subset(wsNoPlat,
  #                        (Source == "Bulk")), 
  #            method = "lm", formula = y ~ poly(x, 2), se = T, aes(colour = 'Bulk'), alpha = 0.2, size=0.2) +
  theme_bw() + 
  # Applics
  annotate("text", x = as.POSIXct('2016-03-28 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-05 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-04-13 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  annotate("text", x = as.POSIXct('2016-05-17 08:04:00'), y = 0, 
           label = as.character(expression(paste( "\u066D"))), parse = T, size = 6.0) +
  # Title applics
  annotate("text", x = as.POSIXct('2016-04-01 08:04:00'), y = 7.5, 
           label = as.character(expression(paste( "\u066D", " Applications"))), parse = T, size = 4.0) +
  
  scale_x_datetime(breaks = date_breaks("2 weeks"), labels = date_format("%b %d")) +
  theme(legend.position="top"
        # axis.title.x = element_blank(),
        # axis.text.x=element_text(angle = 45, hjust = 1)
        ) +
  # geom_smooth(data=subset(ws, Source != "Outlet"), method = "lm", formula = y ~ poly(x, 2)) +
  xlab("Date") + 
  #ylab(expression(paste({Delta~delta}^"13","C", ' (\u2030)'))) +
  scale_y_continuous(
    expression(paste({Delta~delta}^"13","C", ' (\u2030)')), 
    sec.axis = sec_axis(trans = ~ (1-((1000 + d13Co + .)/(1000+d13Co))^(1000/epsilon_field))*100 , 
                        name = "Degr (%)", breaks=c(20, 40, 60, 80, 95) )# breaks=seq(20, 120, 15))
  ) +
  geom_text_repel(aes(label=as.factor(Week)),
                 size = 3,
                  arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
                  force = 0.5, 
                  point.padding = unit(0.5, 'lines'), 
                 max.iter = 2e3,
                nudge_x = .05) 

# + 
  #scale_color_manual(name= "Source", 
  #                    values = c("black", "dodgerblue", "green", "red")
  #                   ) +
  # scale_shape_manual(name= )

wsPlot
```



## Testing difference in $\Delta \delta$ between groups

Based on ANOVA tests, there is:

- No significant difference between soils and water

```{r}
names(WaterSoils)
keepDDtest <- c(
  "Date.ti",
  "diss.d13C.x", # "DD13C.diss",
  "comp.d13C.North", "comp.d13C.Talweg", "comp.d13C.South" #,
  #"DD13C.North", "DD13C.Talweg", "DD13C.South"
)

wsStatTest <- WaterSoils[, colnames(WaterSoils) %in% keepDDtest]

mwsStatTest <- melt(wsStatTest, id="Date.ti")
mwsStatTest$Group1 <- ifelse(mwsStatTest$variable == "diss.d13C.x", "Outlet", "Soil")
mwsStatTest$Group2 <- ifelse(mwsStatTest$variable == "diss.d13C.x", "Outlet", 
                             ifelse(mwsStatTest$variable == "comp.d13C.Talweg", "Valley", "Plateau"))
mwsStatTest$Group3 <- ifelse(mwsStatTest$variable == "diss.d13C.x" & 
                               mwsStatTest$Date.ti > as.POSIXct('2016-06-05 00:06:00', tz = 'EST'), "Outlet(Late)",
                      ifelse(mwsStatTest$variable == "diss.d13C.x" & 
                               mwsStatTest$Date.ti <= as.POSIXct('2016-06-05 00:06:00', tz = 'EST'), "Outlet(Early)",
                      ifelse(mwsStatTest$variable == "comp.d13C.Talweg" & 
                               mwsStatTest$Date.ti > as.POSIXct('2016-06-05 00:06:00', tz = 'EST'), "Valley(Late)",
                      ifelse(mwsStatTest$variable == "comp.d13C.Talweg" & 
                               mwsStatTest$Date.ti <= as.POSIXct('2016-06-05 00:06:00', tz = 'EST'), "Valley(Early)",
                      ifelse( (mwsStatTest$variable == "comp.d13C.North" | mwsStatTest$variable == "comp.d13C.South") &
                               mwsStatTest$Date.ti <= as.POSIXct('2016-06-05 00:06:00', tz = 'EST'), "Plateau(Early)", 
                      ifelse( (mwsStatTest$variable == "comp.d13C.North" | mwsStatTest$variable == "comp.d13C.South") &
                               mwsStatTest$Date.ti > as.POSIXct('2016-06-05 00:06:00', tz = 'EST'), "Plateau(Late)", NA
                              ))))))

Gr1 <- na.omit(mwsStatTest[, colnames(mwsStatTest) %in% c("value", "Group1")])
Gr2 <- na.omit(mwsStatTest[, colnames(mwsStatTest) %in% c("value", "Group2")])
Gr3 <- na.omit(mwsStatTest[, colnames(mwsStatTest) %in% c("value", "Group3")])


# Test for homogeneity of variance
# Large p-value means no confirmation of homogeneity of variance
bartlett.test(value ~ as.factor(Group3), data = Gr3)

# Non-parameteric
# Reject Ho that pop. means are the same if low p-value
res.krs.Grp3 <- kruskal.test(value ~ as.factor(Group3), data = Gr3)
res.krs.Grp3

# Want a TukeyHSD function, but this only works with
# parametric data. So, will pass the ranks of the data instead of the actual values
Gr3.ranks <- rank( Gr3$value )
Gr3.groups <- Gr3$Group3
group3.aov <- aov(Gr3.ranks ~ Gr3.groups) 
res.grp3 <- TukeyHSD(group3.aov, ordered = T)
aov.res.grp3.df <- as.data.frame(res.grp3$Gr3.groups)
aov.res.grp3.df$P <- round(aov.res.grp3.df$`p adj`, 3)
# High p-value indicates no significant difference
write.csv(aov.res.grp3.df, "aovResISOs_ranked.csv", row.names = T)
```

## ANOVA and ANOSIM
Not actually used, as Grouping 3 does not have homegenity of variance 

```{r}

# Simple ANOVA tests 
# (high p-value indicates lack of difference)
# Big P-value no significant difference
boxplot(Gr1$value ~ Gr1$Group1)
summary(aov(Gr1$value ~ Gr1$Group1))
TukeyHSD(aov(Gr1$value ~ Gr1$Group1))

boxplot(Gr3$value ~ Gr3$Group3)
group3.aov <- aov(Gr3$value ~ Gr3$Group3)
summary(group3.aov)



# Transform data and compute dissimilarity
Gr1.hell <- decostand(Gr1[ , 1], "hellinger", na.rm=T, MARGIN = 2) # Transform/Standardize
Gr1.hell.daisy = daisy(Gr1.hell, "euclidean") # Dissimilarity
attach(Gr1)
anosim.group1 <- anosim(Gr1.hell.daisy, grouping = Group1)
summary(anosim.group1)

Gr2.hell <- decostand(Gr2[ , 1], "hellinger", na.rm=T, MARGIN = 2) # Transform/Standardize
Gr2.hell.daisy = daisy(Gr2.hell, "euclidean") # Dissimilarity
attach(Gr2)
anosim.group2 <- anosim(Gr2.hell.daisy, grouping = Group2)
summary(anosim.group2)

Gr3.hell <- decostand(Gr3[ , 1], "hellinger", na.rm=T, MARGIN = 2) # Transform/Standardize
Gr3.hell.daisy = daisy(Gr3.hell, "euclidean") # Dissimilarity
attach(Gr3)
anosim.group3 <- anosim(Gr3.hell.daisy, grouping = Group3)
summary(anosim.group3)

plot(anosim.group3)
```


### Loadings

```{r}
keepLoads <- c("Date.ti",
            "DissOXA.g", "DissESA.g", "DissSmeto.g", "FiltSmeto.g", 
            "Event.x", "Events")
wsLoads <- WaterSoils[ , (names(WaterSoils) %in% keepLoads)]

mw.SM <- 283.796 # g/mol
mw.MOXA <- 279.33 # g/ml
mw.MESA <- 329.1 # g/mol
wsLoads$TPsmeq.g <- 
  wsLoads$DissOXA.g * (mw.SM/mw.MOXA) +
  wsLoads$DissESA.g * (mw.SM/mw.MESA)

wsLoads <- wsLoads[ , !(names(wsLoads) %in% c("DissOXA.g", "DissESA.g"))]

loads <- melt(wsLoads, id=c("Date.ti", "Events", "Event.x"))
 
ggplot(data = loads , aes(x=Events, y=value, fill = variable))+
  theme_bw() +
  geom_bar(stat = "identity") +
  theme(# legend.position="top"
        # axis.title.x = element_blank(),
        axis.text.x=element_text(angle = 45, hjust = 1)
        )
  # geom_bar(stat = "identity", position = position_dodge())

WaterSoils$DIE <- WaterSoils$maxQ*WaterSoils$Volume.m3/WaterSoils$Duration.Hrs

keepCor <- c("maxQ", "Duration.Hrs", "AveDischarge.m3.h", "Volume.m3", "DIE",
            "DissOXA.g", "DissESA.g", "DissSmeto.g", "FiltSmeto.g" #,
            #"NH4.mM", "TIC.ppm.filt", "Cl.mM", "NO3..mM", "PO4..mM", "NPOC.ppm", 
            #"TIC.ppm.unfilt", "TOC.ppm.unfilt"
            )

corData <- WaterSoils[ , (names(WaterSoils) %in% keepCor)]

# Transform / normalize
corData.hell <- decostand(corData, "hellinger", na.rm=T, MARGIN = 2)

library(psych)
pairs.panels(corData)

library(PerformanceAnalytics)
chart.Correlation(corData.hell)


keepLoads <- c("Date.ti",
            "DissOXA.g", "DissESA.g", "DissSmeto.g", "FiltSmeto.g", 
            "Event.x", "Events")
wsLoads <- WaterSoils[ , (names(WaterSoils) %in% keepLoads)]


```

# Outliers

```{r}
# Test function
g_param = 1.5
# g_param = 2.2  #  (Hoaglin et al.,1986; Hoaglin & Iglewicz, 1987) 
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - g_param * IQR(x) | x > quantile(x, 0.75) + g_param * IQR(x))
}


```


## Soil concentrations

Correlation will be made after variable transformation. Options tested:

a) Z-scoring transformation by translation and expansion is done to create unit-free variables with means of zero and standard deviations of one. Standardised values differ from one another in units of standard deviation. The mean of each variable is subtracted from the original values and the difference divided by the variable's standard deviation and is given by:

$$ z_i = \frac{y_i - \bar{y}}{s_y} $$

Z-scoring did not change correlation results, nor outlier reduction.

b) Scaling by expansion where all values are divided by the maximum observation.

### Outliers before transformation

```{r}

# Concentrations
soilGroups %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(Conc.mug.g.dry.soil), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = Conc.mug.g.dry.soil)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)

```

### Outliers after transformation

```{r}
soilGroups <- soilGroups %>%
  group_by(Transect) %>%
  mutate(z_conc = (Conc.mug.g.dry.soil-mean(Conc.mug.g.dry.soil))/sd(Conc.mug.g.dry.soil))


soilGroups %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(z_conc), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = z_conc)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)
```

## Soil Isotopes

```{r}
# Isotopes

temp <- na.omit(soilGroups)

temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(comp.d13C), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = comp.d13C)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)


```

Looks like 7 potential outliers in concentrations and 1 for isotopes. Removing NA's for isotopes and re-computing outliers, reduces the number of outliers to 2 in concentrations and 1 for isotopes. 

```{r}
temp <- temp %>%
  group_by(Transect) %>%
  mutate(z_d13C = (comp.d13C-mean(comp.d13C))/sd(comp.d13C))

temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(z_d13C), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = z_d13C)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)

```



# Distribution of z values (same as non-transformed)

```{r}
# plot densities 
#sm.density.compare(temp$z_conc, temp$Transect, xlab=expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)})))
sm.density.compare(temp$z_conc, temp$Transect, xlab=expression(paste("Conc. S-Meto.  Z-values")))
title(main="Catchment Soil - Concentrations")
legend("topright", levels( soilGroups$Transect), fill=2+(0:nlevels(soilGroups$Transect)))
       
#vioplot(soilGroups$Conc.mug.g.dry.soil,  names = "Catchment")
#title(expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)})))
```

## Soil Isotopes

```{r}
#vioplot(na.omit(soilGroups$comp.d13C),  names = "Catchment")
#title(expression(paste({delta}^"13","C", ' (\u2030)')))
```

```{r}

temp <- na.omit(soilGroups)
sm.density.compare(temp$comp.d13C, temp$Transect, 
                   xlab=expression(paste({delta}^"13","C", ' (\u2030)')))
title(main="Catchment Soil - Isotope Distribution")
legend("topright", levels( soilGroups$Transect), fill=2+(0:nlevels(soilGroups$Transect)))
```


```{r}

```


