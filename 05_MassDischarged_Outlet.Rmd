---
title: "Mass Discharge - Outlet Alteck. 2016"
author: "PAZ"
date: "27 octobre 2016"
output: pdf_document
---


```{r, echo=FALSE, message=FALSE, include=FALSE}
Sys.setlocale("LC_ALL", "English")
```

## Purpose

This file computes the discharged mass observed at the outlet. To do that it imports lab results for isotopes ($^{13}C$) and s-metolachlor concentrations, as well as the weekly discharge summary.

Imports: 

- **WeeklyHydro_R.csv** (R generated)
- **fluxAlteck2016_R.csv** (R generated)


- **OutletConc_W0toW17.csv**
- **MESAlteckWater.csv**     (Concentration in filters)

- **Outlet_Isotopes_W0toW17.csv**
- **MESAlteck_FilterIsotopes.csv** (Isotopes in filters)

- **Outlet_ESAOXA_W0toW17.csv**

- **AO-Hydrochem.csv**

Generates:

- **WeeklyHydroContam_R.csv**

## Required R-packages:

```{r, message=FALSE}

library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")

```

## Working directory

```{r, message=FALSE}

# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()

```
## Lab and reference values

```{r}
# Pure and cuve isotope average
d13Co = -32.25

# Lab enrichment:
# epsilon = -1.61

# Lab enrichment:
# Alteck
#epsilon_max = -1.5 # +/- 0.3 (@ 20C, 20% vwc)
#epsilon_min = -2.0 # +/- 0.2 (@ 20C, 40% vwc)
#epsilon_mean = -1.75

# Ehssan values:
epsilon_max = -1.8 
epsilon_min = -2.6 
epsilon_mean = -2.2 # ± 0.4

# Field values, after dilution correction (Van Breukelen 2008):
# Calculated in Book 9.1
epsilonField_max = -1.7 + 0.33 
epsilonField_min = -1.7 - 0.33  
epsilonField_mean = -1.7 # ± 0.33

```


## Outlet Data - Alteckendorf 2016

1. Hydrological data on a subweekly basis

```{r, message=FALSE}

weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)

weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)


```

2. Concentration data (dissolved and suspended solids) on a subweekly basis

```{r, message=FALSE}

outletConc = read.csv2("Data/OutletConc_W0toW17.csv", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD")]
head(outletConc)

filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)

# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)

means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL

head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)

head(outletESAOXA)
```

3. Isotope data


Isotopes selected where cleaned according to the following rules:

a) The isotope shift was not largely beyond (2x) Streitwieser theoretical limits (i.e. > 10)
b) Isotope shift was non-negative
c) Nanograms of carbon > 2.0.

```{r, message=FALSE}

# Outlet isotope data:

outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
  outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
str(outletIso)

colnames(outletIso)
outletIso$DD13 <- outletIso$d.13C.12C - -32.253

# Filter isotope data:
filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
  filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"

str(filtersIso)

```

4. Hydrochemistry Data

```{r, message=FALSE}

hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek", 
                          "NH4.mM", 
                          "TIC.ppm.filt", 
                          "Cl.mM", 
                          "NO3...mM", 
                          "PO4..mM", 
                          "NPOC.ppm" ,
                          "TIC.ppm.unfilt", 
                          "TOC.ppm.unfilt" )]
head(hydroChem)

```


## Summarizing IRMS data

```{r, message=FALSE}


outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
                         N    = length(d.13C.12C),
                         diss.d13C = mean(d.13C.12C),
                         SD.d13C = sd(d.13C.12C),
                         # se.d13C = SD.d13C / sqrt(N), 
                         N_d13C.diss = length(d.13C.12C))
                      

isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
                         N    = length(d.13C.12C),
                         filt.d13C = mean(d.13C.12C),
                         filt.SD.d13C = sd(d.13C.12C) #,
                         # filt.se.d13C = filt.SD.d13C / sqrt(N),
                         # N_ngC.fl = length(ngC),
                         # ngC.mean.fl = mean(ngC),
                         # ngC.SD.fl = sd(ngC)
                       )
head(isoFiltSummary)
```


## Merging and data wrangling stepts

1. Merge all data sets by the *WeekSubWeek* column ID, icluding:

```{r}

# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)

# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)

# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))


# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)

# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)


# Hydrochemistrty
out.CoIs = merge(out.CoIs, hydroChem, by= "WeekSubWeek", all = T)


out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))

# Temprarily remove Weeks 16 & 17 (need to get discharge data)
# No discharge data yet avaialble to multiply against...
out.CoIs <- out.CoIs[!is.na(out.CoIs$tf), ]

```

2. Weekly Exported Solids (Kg)

```{r}
# V[m3] * MES [mg/L] * 1000 [L/m3] * [1 Kg/10^6 mg]
out.CoIs$ExpMES.Kg = out.CoIs$Volume.m3*out.CoIs$MES.mg.L/1000
```

## Fork! Prepare Data for C-Q Hysteresis curves

```{r}
CQdata <- out.CoIs[with(out.CoIs, order(ti)), ]
CQdata$FlowType <- ifelse(is.na(CQdata$Event), "Fall", "Peak")
CQdata$Event[1:3]<- 0
CQdata$EventMark <- NA

CQdata$EventMark <- na.locf(CQdata$Event)

CQdata$EventMark <- ifelse(is.na(CQdata$Event), CQdata$EventMark, CQdata$EventMark*10)
CQdata$Row <- seq.int(nrow(CQdata))

cq1 <- subset(CQdata[1:6, ])

cq1 <- cq1[cq1$Sampled != 'Not Sampled', ]

str(cq1)
 
#p <- ggplot(cq1) + 
#  geom_point(aes(x=AveDischarge.m3.h, y=Conc.mug.L), colour="black") +
#  geom_polygon(aes(x=AveDischarge.m3.h, y=Conc.mug.L), colour="black", fill = NA) +
  
#  geom_text(data = cq1, 
#            aes(x=AveDischarge.m3.h, y=Conc.mug.L, label=FlowType), hjust=1.5, vjust=0.5, size = 2)
# p

#p <- ggplotly(p)
#p
```


## Section to UPDATE!!!

3. Weekly exported S-metolachlor mass (mg)

This section converts the observed S-metolachlor concentrations to [mg] in dissolved water and suspended solids. For non-sampled subsets a linear interpolation value based on the trailing and leading observed concentrations was assumed. An approximative model will be tested at a later stage. 

To revise: SD for filtered samples!!

```{r}
# Assume first observation is equivalent to second for all measured values
out.CoIs[1, c("Conc.mug.L")] <- out.CoIs[2, c("Conc.mug.L")]
out.CoIs[1, c("Conc.SD")] <- out.CoIs[2, c("Conc.SD")]

out.CoIs[1, c("OXA_mean")] <- out.CoIs[2, c("OXA_mean")]
out.CoIs[1, c("OXA_SD")] <- out.CoIs[2, c("OXA_SD")]

out.CoIs[1, c("ESA_mean")] <- out.CoIs[2, c("ESA_mean")]
out.CoIs[1, c("ESA_SD")] <- out.CoIs[2, c("ESA_SD")]

out.CoIs[1, c("Conc.Solids.mug.gMES")] <- out.CoIs[2, c("Conc.Solids.mug.gMES")]
out.CoIs[1, c("Conc.Solids.ug.gMES.SD")] <- out.CoIs[2, c("Conc.Solids.ug.gMES.SD")]

out.CoIs[1, c("ExpMES.Kg")] <- out.CoIs[2, c("ExpMES.Kg")]

# Assign linear approximation of trailing and leading observed values
out.CoIs <- out.CoIs[with(out.CoIs , order(ti)), ]

out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
out.CoIs$Conc.SD <- na.approx(out.CoIs$Conc.SD)

out.CoIs$OXA_mean <- na.approx(out.CoIs$OXA_mean)
out.CoIs$OXA_SD <- na.approx(out.CoIs$OXA_SD)

out.CoIs$ESA_mean <- na.approx(out.CoIs$ESA_mean)
out.CoIs$ESA_SD <- na.approx(out.CoIs$ESA_SD)

out.CoIs$Conc.Solids.mug.gMES <- na.approx(out.CoIs$Conc.Solids.mug.gMES)
out.CoIs$Conc.Solids.ug.gMES.SD <- na.approx(out.CoIs$Conc.Solids.ug.gMES.SD)

out.CoIs$ExpMES.Kg <- na.approx(out.CoIs$ExpMES.Kg)

```

4. Add the application dates and merge the total mass to the nearest discharge event

The 4 application dates were:

- 2016-03-20 (Friess, Beet) and 2016-03-25 (Matthis, Beet)
- 2016-04-13 and 2016-04-14 (Kopp and Burger, Beet)
- 2016-05-25 (Schmidt, Talweg, Corn)
- 2016-06-04 (Assumed Speich and Mahler, Corn not on transect, Except Speich N1)

To compute initial concentration needed for Rayleigh calculations, the application rates are used to derive the respective concentration at each plot $C_i$, plot area $A$ and the effective transect area $A_tr$ (i.e. proportional to sampling points along transect, not extrapolated area represented by transect within entire catchment). 

Note that initial concentrations at each transect will be later extrapolated to the catchment to calculate initial catchment concentrations (bulk), which in turn do take into account the full catchment area.

$$\sum_i C_{i} \cdot \frac{A_{i}}{A_{tr}}$$

So the total applied mass mass is merged at the nearest sampling time marker available : 

```{r}

ti = c(as.POSIXct('2016-03-25 00:04:00' , tz="EST"),
#       as.POSIXct('2016-04-05 15:08:00' , tz="EST"),
       as.POSIXct('2016-04-14 13:52:00' , tz="EST"),
       as.POSIXct('2016-05-29 12:10:00' , tz="EST"),
       # as.POSIXct('2016-05-24 12:00:00' , tz="EST"),
       as.POSIXct('2016-06-04 15:32:00' , tz="EST"))

# Appl.Mass.g = c(17319.059, 4744.571, 1891.742, 6826.825) # With Friess applying MG's doses for Beet 
# Appl.Mass.g = c(33242.550, 4744.571, 1891.742, 6826.825) # With Friess applying DG's doses instead of MG's
# Appl.Mass.g = c(31670.073, 4744.571, 1803.066, 6506.818) # With Friess applying MG's doses for Corn 
Appl.Mass.g = c(31670.073, 12316.197, 1803.066, 6506.818) # With Kopp applying MG's doses for Corn, not Beet 


### With Kopp applying MG's doses for Corn, not Beet 
# Appl.Mass.g.OT = c(24477.491, 12249.068, 1803.066, 4454.233) 
# Appl.Mass.g.OT = c(14648.725, 12249.068, 1803.066, 6307.544) # Friess's, S-15 on transect
Appl.Mass.g.OT = c(24477.491, 12249.068, 1803.066, 6307.544) # Friess & Kopp applying MG's doses for Corn, not Beet

### With Kopp applying MG's doses for Corn, not Beet &
# Matthis applying extra DG's doses for Corn, or using slightly higher MG doses 
# Appl.Mass.g.OT = c(27076.406, 12249.068, 1803.066, 4454.233) 

Appl.Mass.g.N <- c(8429.434, 7810.101, 0, 5346.189)
Appl.Mass.g.N.OT <- c(8429.434, 7810.101, 0, 3293.605) # Friess with DG
# Appl.Mass.g.N.OT <- c(2528.830, 7810.101, 0, 3293.605) # Friess with MG

Appl.Mass.g.T <- c(6903.610, 3073.636, 1803.066, 0)
Appl.Mass.g.T.OT <- c(2727.322, 3006.507, 1803.066, 0) # Friess with DG
# Appl.Mass.g.T.OT <- c(818.196, 3006.507, 1803.066, 0) # Friess with MG

Appl.Mass.g.S <- c(16337.030, 1432.460, 0, 1160.628)
## Options:
# 1
# Appl.Mass.g.S.OT <- c(13320.736, 1432.460, 0, 1160.628)
Appl.Mass.g.S.OT <- c(13320.736, 1432.460, 0, 3016.294) # Friess's S-15 on transect
# Appl.Mass.g.S.OT <- c(11301.698, 1432.460, 0, 3016.294) # Friess's S-15 on transect, Freiss with MG for Beet

# 2 
# Matthis applying DG's doses for Corn, but using MG 
# Appl.Mass.g.S.OT <- c(15919.651, 1432.460, 0, 1160.628)

# Initial soil concentration (needed for Rayleigh calculations later)

# Effective area [m2] refers to plot area touched by a transect, not sub-catchment area.
# Need this to calculate initial concentration.
Narea_eff <- 101721.702
Tarea_eff <- 39247.330
Sarea_eff <- 109903.101 # With S-15 (Friess Corn) on Transect

MGplotConc.Corn <- 19.592 # Assume for Friess, as he grew both Corn and Beet 
MGplotConc.Beet <- 5.878 # ug/g soil for Mercantor Gold
DGplotConc <- 19.607 # Dual Gold
# MGbutDG.Matthis <- 24.490

### Initial concentrations: 

# First applciations
north_first <- 
  # MGplotConc.Beet*(43903.301/Narea_eff) # Friess Area fraction, ug/g
  MGplotConc.Corn*(43903.301/Narea_eff) # Friess Area fraction, ug/g

talweg_first <- 
  # MGplotConc.Beet*(14204.800/Tarea_eff) # Friess
  MGplotConc.Corn*(14204.800/Tarea_eff) # Friess
  # DGplotConc*(14204.800/Tarea_eff) # Friess

south_first <- 
  # MGplotConc.Beet*(15022.6/Sarea_eff)+ # Friess, S-11
  MGplotConc.Corn*(15022.6/Sarea_eff)+ # Friess, S-11
  # DGplotConc*(15022.6/Sarea_eff)+ # Friess, S-11
  # DGplotConc*(15697.6/Sarea_eff)+ # Friess, S-15  # Now or in May??
  # MGplotConc.Beet*(54313.801/Sarea_eff) # Mathis area/area_tot.S
  DGplotConc*(54313.801/Sarea_eff) # Mathis area/area_tot.S
  #MGbutDG.Matthis*(54313.801/Sarea_eff) # Mathis area/area_tot.S
  
# Second applications
north_second <- 
  north_first+
  MGplotConc.Corn*(9452.500/Narea_eff+ # Kopp, N-4
                     13776.500/Narea_eff+ # Kopp, N-7
                     17448.600/Narea_eff) # Kopp, N-8
talweg_second <- 
  talweg_first+
  MGplotConc.Corn*(2965.980/Tarea_eff # Kopp, T-4
                   + 5336.080/Tarea_eff # Kopp, T-7
                   + 7356.830/Tarea_eff) # Kopp, T-8
south_second <- 
  south_first +
  MGplotConc.Beet*(24869.100/Sarea_eff) # Burger

# Third applications
north_third <- north_second

talweg_third <- 
  talweg_second+
  DGplotConc*(9383.640/Tarea_eff) # Schmitt, T-10

south_third <- south_second

# Fourth applications
north_fourth <- 
  north_second+
  # MGplotConc.Corn*(17140.801/Narea_eff) # Speich Corn with MG
  DGplotConc*(17140.801/Narea_eff) # Speich Corn with DG

talweg_fourth <- talweg_third
# south_fourth <- south_second # If Speich's S-70 not in transect
south_fourth <- south_second +
  MGplotConc.Corn*(6040.220/Narea_eff) + # Speich Corn with MG (South Transect)
  DGplotConc*(15697.6/Sarea_eff) # Friess, S-15  # Now or in April??

applics = as.data.frame(ti)
applics$Appl.Mass.g = Appl.Mass.g
applics$Appl.Mass.g.OT = Appl.Mass.g.OT
applics$Appl.Mass.g.N = Appl.Mass.g.N
applics$Appl.Mass.g.T = Appl.Mass.g.T
applics$Appl.Mass.g.S = Appl.Mass.g.S

applics$Appl.Mass.g.N.OT = Appl.Mass.g.N.OT
applics$Appl.Mass.g.T.OT = Appl.Mass.g.T.OT
applics$Appl.Mass.g.S.OT = Appl.Mass.g.S.OT

applics$iniCo.ug.g.N = c(north_first, north_second, north_third, north_fourth)
applics$iniCo.ug.g.T = c(talweg_first, talweg_second, talweg_third, talweg_fourth)
applics$iniCo.ug.g.S = c(south_first, south_second, south_third, south_fourth)

out.CoIs = merge(out.CoIs, applics, by = "ti", all = T)

out.CoIs$Appl.Mass.g <- ifelse(is.na(out.CoIs$Appl.Mass.g), 0.0, out.CoIs$Appl.Mass.g)
out.CoIs$Appl.Mass.g.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.OT), 0.0, out.CoIs$Appl.Mass.g.OT)

out.CoIs$Appl.Mass.g.N <- ifelse(is.na(out.CoIs$Appl.Mass.g.N), 0.0, out.CoIs$Appl.Mass.g.N)
out.CoIs$Appl.Mass.g.T <- ifelse(is.na(out.CoIs$Appl.Mass.g.T), 0.0, out.CoIs$Appl.Mass.g.T)
out.CoIs$Appl.Mass.g.S <- ifelse(is.na(out.CoIs$Appl.Mass.g.S), 0.0, out.CoIs$Appl.Mass.g.S)

out.CoIs$Appl.Mass.g.N.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.N.OT), 0.0, out.CoIs$Appl.Mass.g.N.OT)
out.CoIs$Appl.Mass.g.T.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.T.OT), 0.0, out.CoIs$Appl.Mass.g.T.OT)
out.CoIs$Appl.Mass.g.S.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.S.OT), 0.0, out.CoIs$Appl.Mass.g.S.OT)

out.CoIs$timeSinceApp <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g'] != 0){
    out.CoIs[i,]['timeSinceApp'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp']
  }
}

out.CoIs$timeSinceApp.N <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.N'] != 0){
    out.CoIs[i,]['timeSinceApp.N'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.N'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.N']
  }
}

out.CoIs$timeSinceApp.T <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.T'] != 0){
    out.CoIs[i,]['timeSinceApp.T'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.T'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.T']
  }
}

out.CoIs$timeSinceApp.S <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.S'] != 0){
    out.CoIs[i,]['timeSinceApp.S'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.S'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.S']
  }
}

# Not in South
out.CoIs$Appl.Mass.g.NoSo <- out.CoIs$Appl.Mass.g
out.CoIs$Appl.Mass.g.NoSo[which(out.CoIs$ti == as.POSIXct('2016-05-23 18:02:00' , tz="EST"))] <- 0
out.CoIs$timeSinceApp.NoSo <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.NoSo'] != 0){
    out.CoIs[i,]['timeSinceApp.NoSo'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.NoSo'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.NoSo']
  }
}


out.CoIs$timeSinceApp <- round(out.CoIs$timeSinceApp/24, 1) # Convert to days
out.CoIs$timeSinceApp.NoSo <- round(out.CoIs$timeSinceApp.NoSo/24, 1)
out.CoIs$timeSinceApp.N <- round(out.CoIs$timeSinceApp.N/24, 1) # Convert to days
out.CoIs$timeSinceApp.T <- round(out.CoIs$timeSinceApp.T/24, 1) # Convert to days
out.CoIs$timeSinceApp.S <- round(out.CoIs$timeSinceApp.S/24, 1) # Convert to days

# Cumulative (Continous)
out.CoIs$CumAppMass.g = cumsum(out.CoIs$Appl.Mass.g)
out.CoIs$CumAppMass.g.OT = cumsum(out.CoIs$Appl.Mass.g.OT)
out.CoIs$CumAppMass.g.N = cumsum(out.CoIs$Appl.Mass.g.N)
out.CoIs$CumAppMass.g.T = cumsum(out.CoIs$Appl.Mass.g.T)
out.CoIs$CumAppMass.g.S = cumsum(out.CoIs$Appl.Mass.g.S)
out.CoIs$CumAppMass.g.N.OT = cumsum(out.CoIs$Appl.Mass.g.N.OT)
out.CoIs$CumAppMass.g.T.OT = cumsum(out.CoIs$Appl.Mass.g.T.OT)
out.CoIs$CumAppMass.g.S.OT = cumsum(out.CoIs$Appl.Mass.g.S.OT)

out.CoIs$iniCo.ug.g.N = na.locf(out.CoIs$iniCo.ug.g.N)
out.CoIs$iniCo.ug.g.T = na.locf(out.CoIs$iniCo.ug.g.T)
out.CoIs$iniCo.ug.g.S = na.locf(out.CoIs$iniCo.ug.g.S)


```


## Section to UPDATE!!!

5. This section is based on approximate carried-last-observation for the observed concentration data (if no model has been conducted yet). 

Also, mass equivalent loads are calculated such that:

$$
MEQ_{SMET} = 
  SMET_{out} + OXA_{out} * (\frac{mw_{SMET}}{mw_{MOXA}}) +
  ESA_{out} * (\frac{mw_{SMET}}{mw_{MESA}})
$$

```{r}

# First simulate a mass out to deal with missing values
# Option 1, just assume 0.0 

# Dissolved - [mg] S-metolachlor exported per sub-week
# Conc. [mu.g s-meto/L H20] * Vol[m3] * [10^3 L/m^3] * [1 mg/10^3 mu.g]
out.CoIs$DissSmeto.mg = out.CoIs$Conc.mug.L*out.CoIs$Volume.m3
out.CoIs$DissSmeto.mg.SD = out.CoIs$Conc.SD*out.CoIs$Volume.m3
out.CoIs$DissSmeto.g = out.CoIs$DissSmeto.mg/10^3
out.CoIs$DissSmeto.g.SD = out.CoIs$DissSmeto.mg.SD/10^3

out.CoIs$DissOXA.mg = out.CoIs$OXA_mean*out.CoIs$Volume.m3
out.CoIs$DissOXA.mg.SD = out.CoIs$OXA_SD*out.CoIs$Volume.m3
out.CoIs$DissOXA.g = out.CoIs$DissOXA.mg/10^3
out.CoIs$DissOXA.g.SD = out.CoIs$DissOXA.mg.SD/10^3

out.CoIs$DissESA.mg = out.CoIs$ESA_mean*out.CoIs$Volume.m3 
out.CoIs$DissESA.mg.SD = out.CoIs$ESA_SD*out.CoIs$Volume.m3 
out.CoIs$DissESA.g = out.CoIs$DissESA.mg/10^3
out.CoIs$DissESA.g.SD = out.CoIs$DissESA.mg.SD/10^3

# Solids - [mg] S-metolachlor in solids exported per sub-week 
# Conc. [mu.g s-meto / g MES] * Kg MES * [10^3 g/Kg] * [1 mg/10^3 mu.g]
out.CoIs$FiltSmeto.mg = out.CoIs$Conc.Solids.mug.gMES*out.CoIs$ExpMES.Kg 
out.CoIs$FiltSmeto.mg.SD = out.CoIs$Conc.Solids.ug.gMES.SD*out.CoIs$ExpMES.Kg 
out.CoIs$FiltSmeto.g = out.CoIs$FiltSmeto.mg/10^3
out.CoIs$FiltSmeto.g.SD  = out.CoIs$FiltSmeto.mg.SD/10^3
  
# Total SM
out.CoIs$TotSMout.mg = out.CoIs$DissSmeto.mg + out.CoIs$FiltSmeto.mg
out.CoIs$TotSMout.mg.SD = sqrt(((out.CoIs$DissSmeto.mg.SD)^2 + (out.CoIs$FiltSmeto.mg.SD)^2)/2)
out.CoIs$TotSMout.g = out.CoIs$TotSMout.mg/10^3
out.CoIs$TotSMout.g.SD = out.CoIs$TotSMout.mg.SD/10^3

# Distribution dissolved vs suspended solids
out.CoIs$FracDiss = out.CoIs$DissSmeto.mg/out.CoIs$TotSMout.mg
out.CoIs$FracFilt = out.CoIs$FiltSmeto.mg/out.CoIs$TotSMout.mg

#out.CoIs$DissSmeto.g = ifelse(is.na(out.CoIs$DissSmeto.g), 0.0, out.CoIs$DissSmeto.g)
#out.CoIs$FiltSmeto.g = ifelse(is.na(out.CoIs$FiltSmeto.g), 0.0, out.CoIs$FiltSmeto.g)
#out.CoIs$TotSMout.g = out.CoIs$DissSmeto.g + out.CoIs$FiltSmeto.g

# Need to update this :
# out.CoIs$TotSMout.g.SD = out.CoIs$DissSmeto.g.SD

mw.SM <- 283.796 # g/mol
mw.MOXA <- 279.33 # g/ml
mw.MESA <- 329.1 # g/mol
out.CoIs$MELsm.g <- 
  out.CoIs$TotSMout.g + 
  out.CoIs$DissOXA.g * (mw.SM/mw.MOXA) +
  out.CoIs$DissESA.g * (mw.SM/mw.MESA)

# How to sum a standard deviation
# http://stats.stackexchange.com/questions/25848/how-to-sum-a-standard-deviation
out.CoIs$MELsm.g.SD <- 
  sqrt((out.CoIs$TotSMout.g.SD^2 +
     (out.CoIs$DissOXA.g.SD * (mw.SM/mw.MOXA))^2 +
     (out.CoIs$DissESA.g.SD * (mw.SM/mw.MESA))^2)/3)

# Cumulative OUT
out.CoIs$CumOutDiss.g = cumsum(out.CoIs$DissSmeto.g)
out.CoIs$CumOutFilt.g = cumsum(out.CoIs$FiltSmeto.g)
out.CoIs$CumOutSmeto.g = out.CoIs$CumOutDiss.g + out.CoIs$CumOutFilt.g
out.CoIs$CumOutMELsm.g = cumsum(out.CoIs$MELsm.g)

# Balance
out.CoIs$BalMassDisch.g = out.CoIs$CumAppMass.g - out.CoIs$CumOutMELsm.g

# Mass fraction
massOUT = tail(out.CoIs$CumOutSmeto.g, n=1)
MELsmOUT = tail(out.CoIs$CumOutMELsm.g, n=1)

TotAppl = tail(out.CoIs$CumAppMass.g, n=1)

out.CoIs$prctMassOut = (out.CoIs$TotSMout.g / massOUT)
out.CoIs$FracDeltaOut = (out.CoIs$TotSMout.g / massOUT)*out.CoIs$diss.d13C
out.CoIs$FracDeltaOut = ifelse(is.na(out.CoIs$FracDeltaOut), 0.0, out.CoIs$FracDeltaOut)

BulkDeltaOut = sum(out.CoIs$FracDeltaOut)

```


The total mass discharged (up to Week 15) and bulk isotope signature (up to week 11) was:

```{r}
# Cummulative S-metolachlor [g] discharged (before correction)
cat("SM mass sampled: " , as.character(91.10687))

# Cummulative S-metolachlor [g] discharged
cat("SM mass sampled and non-sampled: ",  as.character(massOUT)) 

# Cummulative MEL-sm [g] discharged
cat("MEL-sm [g] sampled and non-sampled: ",  as.character(MELsmOUT)) 

cat("% Mass applied in discahrge [MEL-sm]: ",  (MELsmOUT/TotAppl)*100)

# Bulk isotope signature
BulkDeltaOut
```



6. Testing a regression tree (ommitted for now)

```{r, echo=F, message=FALSE}

# Regression Tree Example 1

# library("party")

#outCoIs.model <- out.CoIs[, c("chExtreme", "changeflux", "AveDischarge.m3.h", "Volume.m3", "TotMassOut.mg")]

#fit <- ctree(TotMassOut.mg ~ chExtreme + changeflux + AveDischarge.m3.h + Volume.m3, data=na.omit(outCoIs.model))
#plot(fit)

# The model does not improve with more variables. 

# Regression Tree Example 2

#library("rpart")

# grow tree 
#fit <- rpart(TotMassOut.mg ~ AveDischarge.m3.h + Volume.m3 + chExtreme + changeflux,  method="anova", data=outCoIs.model)

#printcp(fit) # display the results 
#plotcp(fit) # visualize cross-validation results 
#summary(fit) # detailed summary of splits

# create additional plots 
#par(mfrow=c(1,2)) # two plots on one page 
#rsq.rpart(fit) # visualize cross-validation results  	

## plot tree 
#plot(fit, uniform=TRUE, main="Regression Tree Total Mass Discharged ")
#text(fit, use.n=TRUE, all=TRUE, cex=.8)

```


## Save files

```{r, message=FALSE}

names(out.CoIs)[names(out.CoIs) == "Event"] <- "Peak"

out.CoIs$Events <- as.factor(c("0-1", "0-2", "0-3",
                         "1-1", "1-2", "1-3", 
                         "2-1", "2-2", "2-3", 
                         "3-1", 
                         "4-1", "4-2", "4-3", "4-4", "4-5",
                         "5-1", 
                         "6-1", "6-2", "6-3",
                         "7-1", 
                         "8-1", "8-2", "8-3",
                         "9-1", "9-2", "9-3", "9-4", "9-5",
                         "10-1", "10-2", "10-3", "10-4", "10-5", 
                         "11-1", 
                         "12-1", "12-2", "12-3",
                         "13-1",
                         "14-1",
                         "15-1", "15-2", "15-3", "15-4", 
                         "16-1", "16-2", 
                         "17-1", "17-2",
                         "18-1", "18-2", "18-3", "18-4"))

# Adding a Weeks column for labelling
out.CoIs$WeekSubWeek <- as.character(out.CoIs$WeekSubWeek)
Split <- strsplit(out.CoIs$WeekSubWeek, "-", fixed = TRUE)
out.CoIs$Weeks <- sapply(Split, "[", 1)

Split2 <- strsplit(as.character(out.CoIs$Events), "-", fixed = T)
out.CoIs$Event <- as.factor(sapply(Split2, "[", 1))

out.CoIs$WeekSubWeek <- factor(out.CoIs$WeekSubWeek, levels = unique(out.CoIs$WeekSubWeek))
out.CoIs$Weeks <- factor(out.CoIs$Weeks, levels = unique(out.CoIs$Weeks))

out.CoIs$Events <- factor(out.CoIs$Events, levels = unique(out.CoIs$Events))
out.CoIs$Event <- factor(out.CoIs$Event, levels = unique(out.CoIs$Event))

head(out.CoIs)

write.csv2(out.CoIs, 
           'Data/WeeklyHydroContam_R.csv', row.names = F)
sum(is.na(out.CoIs$maxQ))

# out.CoIs = read.csv2("Data/WeeklyHydroContam_R.csv")
# out.CoIs$ti = as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")

```

