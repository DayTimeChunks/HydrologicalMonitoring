---
title: "Mass Discharge - Outlet Alteck. 2016"
author: "PAZ"
date: "27 octobre 2016"
output: pdf_document
---


```{r, echo=FALSE, message=FALSE, include=FALSE}
Sys.setlocale("LC_ALL", "English")
```

## Purpose

This file computes the discharged mass observed at the outlet. To do that it imports the weekly discharge summary and lab results for isotopes ($^{13}C$) and s-metolachlor concentrations.

Imports: 

- **WeeklyHydro_R.csv** (R generated)
- **fluxAlteck2016_R.csv** (R generated)


- **OutletConc_W0toW17.csv**
- **MESAlteckWater.csv**     (Concentration in filters)

- **Outlet_Isotopes_W0toW17.csv**
- **MESAlteck_FilterIsotopes.csv** (Isotopes in filters)

- **Outlet_ESAOXA_W0toW17.csv**

- **AO-Hydrochem.csv**

Generates:

- **WeeklyHydroContam_R.csv**

## Required R-packages:

```{r, message=FALSE}

library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")

```

## Working directory

```{r, message=FALSE}

# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()

```
## Lab and reference values

```{r}
# Pure and cuve isotope average
d13Co = -32.25

# Lab enrichment:
# epsilon = -1.61

# Lab enrichment:
# Alteck
#epsilon_max = -1.5 # +/- 0.3 (@ 20C, 20% vwc)
#epsilon_min = -2.0 # +/- 0.2 (@ 20C, 40% vwc)
#epsilon_mean = -1.75

# Ehssan values:
epsilon_max = -1.8 
epsilon_min = -2.6 
epsilon_mean = -2.2 # ± 0.4

# Field values, after dilution correction (Van Breukelen 2008):
# Calculated in Book 9.1
epsilonField_max = -1.7 + 0.33 
epsilonField_min = -1.7 - 0.33  
epsilonField_mean = -1.7 # ± 0.33

```


## Outlet Data - Alteckendorf 2016

1. Hydrological data on a subweekly basis

```{r, message=FALSE}

weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)

weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)
```

2. Concentration data (dissolved and suspended solids) on a subweekly basis

```{r, message=FALSE}

outletConc = read.csv2("Data/OutletConc_W0toW17.csv", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD")]
head(outletConc)

filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)

# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)

means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL

head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)

head(outletESAOXA)
```

3. Isotope data


Isotopes selected where cleaned according to the following rules:

a) The isotope shift was not largely beyond (2x) Streitwieser theoretical limits (i.e. > 10)
b) Isotope shift was non-negative
c) Nanograms of carbon > 2.0.

```{r, message=FALSE}

# Outlet isotope data:

outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
  outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
head(outletIso)


colnames(outletIso)
colnames(outletIso)[colnames(outletIso) == "DD13...32.25."] <- "DD13"
colnames(outletIso)[colnames(outletIso) == "ng..C."] <- "ngC"

# Filter isotope data:

filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
  filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"

head(filtersIso)

```

4. Hydrochemistry Data

```{r, message=FALSE}

hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek", 
                          "NH4.mM", 
                          "TIC.ppm.filt", 
                          "Cl.mM", 
                          "NO3...mM", 
                          "PO4..mM", 
                          "NPOC.ppm" ,
                          "TIC.ppm.unfilt", 
                          "TOC.ppm.unfilt" )]
head(hydroChem)

```


## Summarizing IRMS data

```{r, message=FALSE}


outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
                         N    = length(d.13C.12C),
                         diss.d13C = mean(d.13C.12C),
                         SD.d13C = sd(d.13C.12C),
                         se.d13C = SD.d13C / sqrt(N), 
                         N_ngC.diss = length(ngC),
                         ngC.mean.diss = mean(ngC),
                         ngC.SD.diss = sd(ngC))
                      


head(isoOutSummary)

sum(isoOutSummary$N_ngC.diss == 2)
sum(isoOutSummary$N_ngC.diss > 2)
sum(isoOutSummary$N_ngC.diss == 2) /(sum(isoOutSummary$N_ngC.diss == 2) + sum(isoOutSummary$N_ngC.diss > 2))

isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
                         N    = length(d.13C.12C),
                         filt.d13C = mean(d.13C.12C),
                         filt.SD.d13C = sd(d.13C.12C),
                         filt.se.d13C = filt.SD.d13C / sqrt(N),
                         N_ngC.fl = length(ngC),
                         ngC.mean.fl = mean(ngC),
                         ngC.SD.fl = sd(ngC))
head(isoFiltSummary)
```


## Merging and data wrangling stepts

1. Merge all data sets by the *WeekSubWeek* column ID, icluding:

```{r}

# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)

# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)

# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))


# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)

# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)

# Hydrochemistrty
out.CoIs = merge(out.CoIs, hydroChem, by= "WeekSubWeek", all = T)


out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))

# Temprarily remove Weeks 16 & 17 (need to get discharge data)
# No discharge data yet avaialble to multiply against...
out.CoIs <- out.CoIs[!is.na(out.CoIs$tf), ]

```

2. Weekly Exported Solids (Kg)

```{r}
# V[m3] * MES [mg/L] * 1000 [L/m3] * [1 Kg/10^6 mg]
out.CoIs$ExpMES.Kg = out.CoIs$Volume.m3*out.CoIs$MES.mg.L/1000
```

## Fork! Prepare Data for C-Q Hysteresis curves

```{r}
CQdata <- out.CoIs[with(out.CoIs, order(ti)), ]
CQdata$FlowType <- ifelse(is.na(CQdata$Event), "Fall", "Peak")
CQdata$Event[1:3]<- 0
CQdata$EventMark <- NA

CQdata$EventMark <- na.locf(CQdata$Event)

CQdata$EventMark <- ifelse(is.na(CQdata$Event), CQdata$EventMark, CQdata$EventMark*10)
CQdata$Row <- seq.int(nrow(CQdata))

cq1 <- subset(CQdata[1:6, ])

cq1 <- cq1[cq1$Sampled != 'Not Sampled', ]

str(cq1)
 
#p <- ggplot(cq1) + 
#  geom_point(aes(x=AveDischarge.m3.h, y=Conc.mug.L), colour="black") +
#  geom_polygon(aes(x=AveDischarge.m3.h, y=Conc.mug.L), colour="black", fill = NA) +
  
#  geom_text(data = cq1, 
#            aes(x=AveDischarge.m3.h, y=Conc.mug.L, label=FlowType), hjust=1.5, vjust=0.5, size = 2)
# p

#p <- ggplotly(p)
#p
```


## Section to UPDATE!!!

3. Weekly exported S-metolachlor mass (mg)

This section converts the observed S-metolachlor concentrations to [mg] in dissolved water and suspended solids. For non-sampled subsets a linear interpolation value based on the trailing and leading observed concentrations was assumed. An approximative model will be tested at a later stage. 

To revise: SD for filtered samples!!

```{r}
# Assume first observation is equivalent to second for all measured values
out.CoIs[1, c("Conc.mug.L")] <- out.CoIs[2, c("Conc.mug.L")]
out.CoIs[1, c("Conc.SD")] <- out.CoIs[2, c("Conc.SD")]

out.CoIs[1, c("OXA_mean")] <- out.CoIs[2, c("OXA_mean")]
out.CoIs[1, c("OXA_SD")] <- out.CoIs[2, c("OXA_SD")]

out.CoIs[1, c("ESA_mean")] <- out.CoIs[2, c("ESA_mean")]
out.CoIs[1, c("ESA_SD")] <- out.CoIs[2, c("ESA_SD")]

out.CoIs[1, c("Conc.Solids.mug.gMES")] <- out.CoIs[2, c("Conc.Solids.mug.gMES")]
out.CoIs[1, c("Conc.Solids.ug.gMES.SD")] <- out.CoIs[2, c("Conc.Solids.ug.gMES.SD")]

out.CoIs[1, c("ExpMES.Kg")] <- out.CoIs[2, c("ExpMES.Kg")]

# Assign linear approximation of trailing and leading observed values
out.CoIs <- out.CoIs[with(out.CoIs , order(ti)), ]

out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
out.CoIs$Conc.SD <- na.approx(out.CoIs$Conc.SD)

out.CoIs$OXA_mean <- na.approx(out.CoIs$OXA_mean)
out.CoIs$OXA_SD <- na.approx(out.CoIs$OXA_SD)

out.CoIs$ESA_mean <- na.approx(out.CoIs$ESA_mean)
out.CoIs$ESA_SD <- na.approx(out.CoIs$ESA_SD)

out.CoIs$Conc.Solids.mug.gMES <- na.approx(out.CoIs$Conc.Solids.mug.gMES)
out.CoIs$Conc.Solids.ug.gMES.SD <- na.approx(out.CoIs$Conc.Solids.ug.gMES.SD)

out.CoIs$ExpMES.Kg <- na.approx(out.CoIs$ExpMES.Kg)

```

4. Add the application dates and merge the total mass to the nearest discharge event

The 4 application dates were:

- 2016-03-20 (Friess, Beet) and 2016-03-25 (Matthis, Beet)
- 2016-04-13 and 2016-04-14 (Kopp and Burger, Beet)
- 2016-05-25 (Schmidt, Talweg, Corn)
- 2016-06-04 (Assumed Speich and Mahler, Corn not on transect, Except Speich N1)

To compute initial concentration needed for Rayleigh calculations, the application rates are used to derive the respective concentration at each plot $C_i$, plot area $A$ and the effective transect area $A_tr$ (i.e. proportional to sampling points along transect, not total area represented by transect or sub-catchment area). 

Note that initial concentrations at each transect will be later extrapolated to the catchment to calculate initial catchment concentrations (bulk), which in turn do take into account the full catchment area.

$$\sum_i C_{i} \cdot \frac{A_{i}}{A_{tr}}$$

So the total applied mass mass is merged at the nearest sampling time marker available : 

```{r}

ti = c(as.POSIXct('2016-03-25 00:04:00' , tz="EST"),
#       as.POSIXct('2016-04-05 15:08:00' , tz="EST"),
       as.POSIXct('2016-04-14 13:52:00' , tz="EST"),
       as.POSIXct('2016-05-29 12:10:00' , tz="EST"),
       # as.POSIXct('2016-05-24 12:00:00' , tz="EST"),
       as.POSIXct('2016-06-04 15:32:00' , tz="EST"))

# Appl.Mass.g = c(17319.059, 4744.571, 1891.742, 6826.825)
Appl.Mass.g = c(33242.550, 4744.571, 1891.742, 6826.825) # With Friess applying DG's doses instead of MG's
# Initial soil concentration (needed for Rayleigh calculations later)

# Effective area [m2] refers to plot area touched by a transect, not sub-catchment area.
# Need this to calculate initial concentration.
Narea_eff <- 101721.702
Tarea_eff <- 39247.330
Sarea_eff <- 94205.501

MGplotConc <- 5.818 # ug/g soil for Mercantor Gold
DGplotConc <- 20.364 # Dual Gold

north_first <- DGplotConc*(43903.301/Narea_eff)
talweg_first <- DGplotConc*(14204.800/Tarea_eff)
south_first <- DGplotConc*(15022.600/Sarea_eff)+DGplotConc*(54313.801/Sarea_eff)
  
north_second <- north_first+MGplotConc*(9452.500/Narea_eff+13776.500/Narea_eff+17448.600/Narea_eff)
talweg_second <- talweg_first+MGplotConc*(2965.980/Tarea_eff + 5336.080/Tarea_eff + 7356.830/Tarea_eff)
south_second <- south_first+MGplotConc*(24869.100/Sarea_eff)

talweg_third <- talweg_second+DGplotConc*(9383.640/Tarea_eff)
north_fourth <- north_second+DGplotConc*(17140.801/Narea_eff)

applics = as.data.frame(ti)
applics$Appl.Mass.g = Appl.Mass.g
applics$iniCo.ug.g.N = c(north_first, north_second, north_second, north_fourth)
applics$iniCo.ug.g.T = c(talweg_first, talweg_second, talweg_third, talweg_third)
applics$iniCo.ug.g.S = c(south_first, south_second, south_second, south_second)

out.CoIs = merge(out.CoIs, applics, by = "ti", all = T)

out.CoIs$Appl.Mass.g <- ifelse(is.na(out.CoIs$Appl.Mass.g), 0.0, out.CoIs$Appl.Mass.g)

out.CoIs$timeSinceApp <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g'] != 0){
    out.CoIs[i,]['timeSinceApp'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp']
  }
}

out.CoIs$Appl.Mass.g.NoSo <- out.CoIs$Appl.Mass.g
out.CoIs$Appl.Mass.g.NoSo[which(out.CoIs$ti == as.POSIXct('2016-05-23 18:02:00' , tz="EST"))] <- 0
out.CoIs$timeSinceApp.NoSo <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.NoSo'] != 0){
    out.CoIs[i,]['timeSinceApp.NoSo'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.NoSo'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.NoSo']
  }
}


out.CoIs$timeSinceApp <- round(out.CoIs$timeSinceApp/24, 1) # Convert to days
out.CoIs$timeSinceApp.NoSo <- round(out.CoIs$timeSinceApp.NoSo/24, 1)

# Cumulative (Continous)
out.CoIs$CumAppMass.g = cumsum(out.CoIs$Appl.Mass.g)
out.CoIs$iniCo.ug.g.N = na.locf(out.CoIs$iniCo.ug.g.N)
out.CoIs$iniCo.ug.g.T = na.locf(out.CoIs$iniCo.ug.g.T)
out.CoIs$iniCo.ug.g.S = na.locf(out.CoIs$iniCo.ug.g.S)


```


## Section to UPDATE!!!

5. This section is based on approximate carried-last-observation for the observed concentration data (if no model has been conducted yet). 

Also, mass equivalent loads are calculated such that:

$$
MEQ_{SMET} = 
  SMET_{out} + OXA_{out} * (\frac{mw_{SMET}}{mw_{MOXA}}) +
  ESA_{out} * (\frac{mw_{SMET}}{mw_{MESA}})
$$

```{r}

# First simulate a mass out to deal with missing values
# Option 1, just assume 0.0 

# Dissolved - [mg] S-metolachlor exported per sub-week
# Conc. [mu.g s-meto/L H20] * Vol[m3] * [10^3 L/m^3] * [1 mg/10^3 mu.g]
out.CoIs$DissSmeto.mg = out.CoIs$Conc.mug.L*out.CoIs$Volume.m3
out.CoIs$DissSmeto.mg.SD = out.CoIs$Conc.SD*out.CoIs$Volume.m3
out.CoIs$DissSmeto.g = out.CoIs$DissSmeto.mg/10^3
out.CoIs$DissSmeto.g.SD = out.CoIs$DissSmeto.mg.SD/10^3

out.CoIs$DissOXA.mg = out.CoIs$OXA_mean*out.CoIs$Volume.m3
out.CoIs$DissOXA.mg.SD = out.CoIs$OXA_SD*out.CoIs$Volume.m3
out.CoIs$DissOXA.g = out.CoIs$DissOXA.mg/10^3
out.CoIs$DissOXA.g.SD = out.CoIs$DissOXA.mg.SD/10^3

out.CoIs$DissESA.mg = out.CoIs$ESA_mean*out.CoIs$Volume.m3 
out.CoIs$DissESA.mg.SD = out.CoIs$ESA_SD*out.CoIs$Volume.m3 
out.CoIs$DissESA.g = out.CoIs$DissESA.mg/10^3
out.CoIs$DissESA.g.SD = out.CoIs$DissESA.mg.SD/10^3

# Solids - [mg] S-metolachlor in solids exported per sub-week 
# Conc. [mu.g s-meto / g MES] * Kg MES * [10^3 g/Kg] * [1 mg/10^3 mu.g]
out.CoIs$FiltSmeto.mg = out.CoIs$Conc.Solids.mug.gMES*out.CoIs$ExpMES.Kg 
out.CoIs$FiltSmeto.mg.SD = out.CoIs$Conc.Solids.ug.gMES.SD*out.CoIs$ExpMES.Kg 
out.CoIs$FiltSmeto.g = out.CoIs$FiltSmeto.mg/10^3
out.CoIs$FiltSmeto.g.SD  = out.CoIs$FiltSmeto.mg.SD/10^3
  
# Total SM
out.CoIs$TotSMout.mg = out.CoIs$DissSmeto.mg + out.CoIs$FiltSmeto.mg
out.CoIs$TotSMout.mg.SD = sqrt(((out.CoIs$DissSmeto.mg.SD)^2 + (out.CoIs$FiltSmeto.mg.SD)^2)/2)
out.CoIs$TotSMout.g = out.CoIs$TotSMout.mg/10^3
out.CoIs$TotSMout.g.SD = out.CoIs$TotSMout.mg.SD/10^3

# Distribution dissolved vs suspended solids
out.CoIs$FracDiss = out.CoIs$DissSmeto.mg/out.CoIs$TotSMout.mg
out.CoIs$FracFilt = out.CoIs$FiltSmeto.mg/out.CoIs$TotSMout.mg

#out.CoIs$DissSmeto.g = ifelse(is.na(out.CoIs$DissSmeto.g), 0.0, out.CoIs$DissSmeto.g)
#out.CoIs$FiltSmeto.g = ifelse(is.na(out.CoIs$FiltSmeto.g), 0.0, out.CoIs$FiltSmeto.g)
#out.CoIs$TotSMout.g = out.CoIs$DissSmeto.g + out.CoIs$FiltSmeto.g

# Need to update this :
# out.CoIs$TotSMout.g.SD = out.CoIs$DissSmeto.g.SD

mw.SM <- 283.796 # g/mol
mw.MOXA <- 279.33 # g/ml
mw.MESA <- 329.1 # g/mol
out.CoIs$MELsm.g <- 
  out.CoIs$TotSMout.g + 
  out.CoIs$DissOXA.g * (mw.SM/mw.MOXA) +
  out.CoIs$DissESA.g * (mw.SM/mw.MESA)

# How to sum a standard deviation
# http://stats.stackexchange.com/questions/25848/how-to-sum-a-standard-deviation
out.CoIs$MELsm.g.SD <- 
  sqrt((out.CoIs$TotSMout.g.SD^2 +
     (out.CoIs$DissOXA.g.SD * (mw.SM/mw.MOXA))^2 +
     (out.CoIs$DissESA.g.SD * (mw.SM/mw.MESA))^2)/3)

# Cumulative OUT
out.CoIs$CumOutDiss.g = cumsum(out.CoIs$DissSmeto.g)
out.CoIs$CumOutFilt.g = cumsum(out.CoIs$FiltSmeto.g)
out.CoIs$CumOutSmeto.g = out.CoIs$CumOutDiss.g + out.CoIs$CumOutFilt.g
out.CoIs$CumOutMELsm.g = cumsum(out.CoIs$MELsm.g)

# Balance
out.CoIs$BalMassDisch.g = out.CoIs$CumAppMass.g - out.CoIs$CumOutMELsm.g

# Mass fraction
massOUT = tail(out.CoIs$CumOutSmeto.g, n=1)
MELsmOUT = tail(out.CoIs$CumOutMELsm.g, n=1)

TotAppl = tail(out.CoIs$CumAppMass.g, n=1)

out.CoIs$prctMassOut = (out.CoIs$TotSMout.g / massOUT)
out.CoIs$FracDeltaOut = (out.CoIs$TotSMout.g / massOUT)*out.CoIs$diss.d13C
out.CoIs$FracDeltaOut = ifelse(is.na(out.CoIs$FracDeltaOut), 0.0, out.CoIs$FracDeltaOut)

BulkDeltaOut = sum(out.CoIs$FracDeltaOut)

```


The total mass discharged (up to Week 15) and bulk isotope signature (up to week 11) was:

```{r}
# Cummulative S-metolachlor [g] discharged (before correction)
cat("SM mass sampled: " , as.character(91.10687))

# Cummulative S-metolachlor [g] discharged
cat("SM mass sampled and non-sampled: ",  as.character(massOUT)) 

# Cummulative MEL-sm [g] discharged
cat("MEL-sm [g] sampled and non-sampled: ",  as.character(MELsmOUT)) 

cat("% Mass applied in discahrge [MEL-sm]: ",  (MELsmOUT/TotAppl)*100)

# Bulk isotope signature
BulkDeltaOut
```



6. Testing a regression tree (ommitted for now)

```{r, echo=F, message=FALSE}

# Regression Tree Example 1

# library("party")

#outCoIs.model <- out.CoIs[, c("chExtreme", "changeflux", "AveDischarge.m3.h", "Volume.m3", "TotMassOut.mg")]

#fit <- ctree(TotMassOut.mg ~ chExtreme + changeflux + AveDischarge.m3.h + Volume.m3, data=na.omit(outCoIs.model))
#plot(fit)

# The model does not improve with more variables. 

# Regression Tree Example 2

#library("rpart")

# grow tree 
#fit <- rpart(TotMassOut.mg ~ AveDischarge.m3.h + Volume.m3 + chExtreme + changeflux,  method="anova", data=outCoIs.model)

#printcp(fit) # display the results 
#plotcp(fit) # visualize cross-validation results 
#summary(fit) # detailed summary of splits

# create additional plots 
#par(mfrow=c(1,2)) # two plots on one page 
#rsq.rpart(fit) # visualize cross-validation results  	

## plot tree 
#plot(fit, uniform=TRUE, main="Regression Tree Total Mass Discharged ")
#text(fit, use.n=TRUE, all=TRUE, cex=.8)

```


## Save files

```{r, message=FALSE}

names(out.CoIs)[names(out.CoIs) == "Event"] <- "Peak"

out.CoIs$Events <- as.factor(c("0-1", "0-2", "0-3",
                         "1-1", "1-2", "1-3", 
                         "2-1", "2-2", "2-3", 
                         "3-1", 
                         "4-1", "4-2", "4-3", "4-4", "4-5",
                         "5-1", 
                         "6-1", "6-2", "6-3",
                         "7-1", 
                         "8-1", "8-2", "8-3",
                         "9-1", "9-2", "9-3", "9-4", "9-5",
                         "10-1", "10-2", "10-3", "10-4", "10-5", 
                         "11-1", 
                         "12-1", "12-2", "12-3",
                         "13-1",
                         "14-1",
                         "15-1", "15-2", "15-3", "15-4", 
                         "16-1", "16-2", 
                         "17-1", "17-2",
                         "18-1", "18-2", "18-3", "18-4"))

# Adding a Weeks column for labelling
out.CoIs$WeekSubWeek <- as.character(out.CoIs$WeekSubWeek)
Split <- strsplit(out.CoIs$WeekSubWeek, "-", fixed = TRUE)
out.CoIs$Weeks <- sapply(Split, "[", 1)

Split2 <- strsplit(as.character(out.CoIs$Events), "-", fixed = T)
out.CoIs$Event <- as.factor(sapply(Split2, "[", 1))

out.CoIs$WeekSubWeek <- factor(out.CoIs$WeekSubWeek, levels = unique(out.CoIs$WeekSubWeek))
out.CoIs$Weeks <- factor(out.CoIs$Weeks, levels = unique(out.CoIs$Weeks))

out.CoIs$Events <- factor(out.CoIs$Events, levels = unique(out.CoIs$Events))
out.CoIs$Event <- factor(out.CoIs$Event, levels = unique(out.CoIs$Event))

head(out.CoIs)

write.csv2(out.CoIs, 
           'Data/WeeklyHydroContam_R.csv', row.names = F)

# out.CoIs = read.csv2("Data/WeeklyHydroContam_R.csv")
# out.CoIs$ti = as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")

```

