---
title: "Mass Discharge - Outlet Alteck. 2016"
author: "PAZ"
date: "27 octobre 2016"
output: pdf_document
---


```{r, echo=FALSE, message=FALSE, include=FALSE}
Sys.setlocale("LC_ALL", "English")
```

## Purpose

This file merges "sub-weekly" (i.e. sample) outlet concentrations (S-met and TPs) and $\delta ^{13}C$ in dissolved and sediment samples. Hydrochemistry variables are also merged.  



To do that it imports lab results for isotopes ($^{13}C$) and s-metolachlor concentrations, as well as the weekly discharge summary (*WeeklyHydro_R.csv*).

Imports: 

- **WeeklyHydro_R.csv** (R generated, Book 3)
- **fluxAlteck2016_R.csv** (R generated, Book 4)


- **OutletConc_W0toW17.csv**
- **MESAlteckWater.csv**     (Concentration in filters)

- **Outlet_Isotopes_W0toW17.csv**
- **MESAlteck_FilterIsotopes.csv** (Isotopes in filters)

- **Outlet_ESAOXA_W0toW17.csv**

- **AO-Hydrochem.csv**

Generates:

- **WeeklyHydroContam_R.csv**

## Required R-packages:

```{r, message=FALSE}

library("stringr")
library("plyr")
library("dplyr")
library("zoo")
library("ggplot2")
library("plotly")

```

## Working directory

```{r, message=FALSE}

# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# setwd("D:/Documents/these_pablo/Alteckendorf2016/00_TransparencyFolder")
getwd()

```
## Lab and reference values

```{r}
source("global.R")
```


## Outlet Data - Alteckendorf 2016

### Hydrological data on a subweekly basis

```{r, message=FALSE}

weeklyhydro = read.csv2("Data/WeeklyHydro_R.csv", header = TRUE)
colnames(weeklyhydro)[colnames(weeklyhydro) == "ID"] <- "WeekSubWeek"
head(weeklyhydro)

weeklyflux = read.csv2("Data/fluxAlteck2016_R.csv", header = TRUE)
head(weeklyflux)


```

### Concentration data (dissolved and suspended solids) on a subweekly basis

```{r, message=FALSE}

outletConc = read.csv2("Data/OutletConc_W0toW17.csv", sep = ",", dec =".", header = T)
outletConc$ID4 <- as.character(outletConc$ID4)
outletConc <- outletConc[outletConc$ID4 != "J+7", ]
outletConc$Vol.SPE.L <- outletConc$Vol.SPE.mL/1000
outletConc <- outletConc[,c("WeekSubWeek", "Conc.mug.L", "Conc.SD", "Vol.SPE.L", "Conc.in500uL")]
head(outletConc)

filters = read.csv2("Data/MESAlteckWater.csv")
filters$MO.mg.L = ifelse(filters$MO.mg.L < 0, 0.0001, filters$MO.mg.L)
head(filters)

# MESA/MOXA data cleaning
outletESAOXA = read.csv2("Data/Outlet_ESAOXA_W0toW17.csv", header = T)
outletESAOXA$ID <- as.character(outletESAOXA$ID)
split <- strsplit(outletESAOXA$ID, "-", fixed = TRUE)
outletESAOXA$ESAOXA_SD <- sapply(split, "[", 4)
split_vor <- strsplit(outletESAOXA$ID, "-SD", fixed = TRUE)
outletESAOXA$ESAOXA_Mean <- sapply(split_vor, "[", 1)

means_temp <- subset(outletESAOXA, is.na(outletESAOXA$ESAOXA_SD))
sd_temp <- subset(outletESAOXA, !is.na(outletESAOXA$ESAOXA_SD))
means_temp$ID <- NULL
sd_temp$ID <- NULL

head(sd_temp)
head(means_temp)
outletESAOXA <- merge(means_temp, sd_temp, by = "ESAOXA_Mean", all = T)
outletESAOXA$ESAOXA_SD.x <- NULL
outletESAOXA$ESAOXA_SD.y <- NULL
split_ID <- strsplit(outletESAOXA$ESAOXA_Mean, "A0-", fixed = T)
outletESAOXA$ID <- sapply(split_ID, "[", 2)
outletESAOXA$ESAOXA_Mean <- NULL
outletESAOXA <- outletESAOXA[ , c("ID", "MOXA.ugL.x", "MOXA.ugL.y", "MESA.ugL.x", "MESA.ugL.y")]
colnames(outletESAOXA) <- c("WeekSubWeek", "OXA_mean", "OXA_SD", "ESA_mean",  "ESA_SD")
outletESAOXA$WeekSubWeek <- as.factor(outletESAOXA$WeekSubWeek)

head(outletESAOXA)
```

### Isotope data


```{r, message=FALSE}

# Outlet isotope data:

outletIso = read.csv2("Data/Outlet_Isotopes_W0toW17.csv", header = T, dec = ".")
if (length(outletIso) == 1){
  outletIso = read.csv("Data/Outlet_Isotopes_W0toW17.csv", header = T)
}
str(outletIso)

colnames(outletIso)
# Correct for extraction shift
outletIso$d.13C.12C = round( (outletIso$d.13C.12C - meanshift_w), 1)
outletIso$DD13 <- outletIso$d.13C.12C - initialDelta

# Filter isotope data:
filtersIso = read.csv2("Data/MESAlteck_FilterIsotopes.csv", header = T, dec = ".")
#filtersIso <- filtersIso[filtersIso$Levl != "J+7", ]
if (length(filtersIso) == 1){
  filtersIso = read.csv("Data/MESAlteck_FilterIsotopes.csv", header = T)
}
colnames(filtersIso)
filtersIso$WeekSubWeek = paste(filtersIso$Week, filtersIso$Num, sep = "-")
colnames(filtersIso)[colnames(filtersIso) == "DD13.32.253."] <- "DD13"
colnames(filtersIso)[colnames(filtersIso) == "ng..C."] <- "ngC"

str(filtersIso)

```

### Hydrochemistry Data

```{r, message=FALSE}

hydroChem = read.csv2("Data/AO-Hydrochem.csv", header = T)
hydroChem = hydroChem[, c("WeekSubWeek", 
                          "NH4.mM", 
                          "TIC.ppm.filt", 
                          "Cl.mM", 
                          "NO3...mM", 
                          "PO4..mM", 
                          "NPOC.ppm" ,
                          "TIC.ppm.unfilt", 
                          "TOC.ppm.unfilt" )]
head(hydroChem)

```


## Summarizing IRMS data

```{r, message=FALSE}


outletIso <- outletIso[complete.cases(outletIso[ , "d.13C.12C"]), ]
isoOutSummary = ddply(outletIso, c("WeekSubWeek"), summarise,
                         N    = length(d.13C.12C),
                         diss.d13C = mean(d.13C.12C),
                         SD.d13C = sd(d.13C.12C),
                         # se.d13C = SD.d13C / sqrt(N), 
                         N_d13C.diss = length(d.13C.12C))
                      

isoFiltSummary = ddply(filtersIso, c("WeekSubWeek"), summarise,
                         N    = length(d.13C.12C),
                         filt.d13C = mean(d.13C.12C),
                         filt.SD.d13C = sd(d.13C.12C) #,
                         # filt.se.d13C = filt.SD.d13C / sqrt(N),
                         # N_ngC.fl = length(ngC),
                         # ngC.mean.fl = mean(ngC),
                         # ngC.SD.fl = sd(ngC)
                       )
head(isoFiltSummary)
```


## Merging and data wrangling stepts

### Merge all data sets by the *WeekSubWeek* column ID, icluding:

```{r}

# Dissolved
out.CoIs = merge(outletConc,  outletESAOXA, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoOutSummary, by = "WeekSubWeek", all = T)

# Filters (MES, Conc.MES)
out.CoIs = merge(out.CoIs, filters, by = "WeekSubWeek", all = T)
out.CoIs = merge(out.CoIs, isoFiltSummary, by= "WeekSubWeek", all = T)

# Remaining fraction
out.CoIs$DD13C.diss <- (out.CoIs$diss.d13C - (d13Co))
out.CoIs$DD13C.filt <- (out.CoIs$filt.d13C - (d13Co))


# Discharge times
out.CoIs = merge(weeklyhydro, out.CoIs, by = "WeekSubWeek", all = T)

# Discharge summary
out.CoIs = merge(weeklyflux, out.CoIs, by = "WeekSubWeek", all = T)




out.CoIs$tf <- as.POSIXct(out.CoIs$tf, "%Y-%m-%d %H:%M", tz = "EST")
out.CoIs$ti <- as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")
class(out.CoIs$tf)
sum(is.na(out.CoIs$tf))

# Delete repeated W6 observation, or with NA in week markers
out.CoIs = out.CoIs[out.CoIs$WeekSubWeek != as.character("W6-3j7") & !is.na(out.CoIs$WeekSubWeek), ]

write.csv(out.CoIs, "Data/MarkerResponse_R05.csv", row.names = F)

# Temprarily remove Weeks 16 & 17 (need to get discharge data)
# No discharge data yet avaialble to multiply against...
# out.CoIs <- out.CoIs[!is.na(out.CoIs$tf), ]

```

### Weekly Exported Solids (Kg)

```{r}
# V[m3] * MES [mg/L] * 1000 [L/m3] * [1 Kg/10^6 mg]
out.CoIs$ExpMES.Kg = out.CoIs$Volume.m3*out.CoIs$MES.mg.L/1000
```

### Weekly exported S-metolachlor mass (mg) - Linear interpolation

This section imputs concentrations missed due to sampler capacity being maxed out. For these subsets a linear interpolation value based on the trailing and leading observed concentrations was assumed. An approximative model will be tested at a later stage. 

To revise: SD for filtered samples!!
Note: Model may need to be improved!!!

```{r}
# Assume first index is equivalent to second for all measured values 
# (i.e. needed for na.approx operation below)
out.CoIs[1, c("Conc.mug.L")] <- out.CoIs[2, c("Conc.mug.L")]
out.CoIs[1, c("Conc.SD")] <- out.CoIs[2, c("Conc.SD")]
out.CoIs[1, c("Vol.SPE.L")] <- out.CoIs[2, c("Vol.SPE.L")]

out.CoIs[1, c("OXA_mean")] <- out.CoIs[2, c("OXA_mean")]
out.CoIs[1, c("OXA_SD")] <- out.CoIs[2, c("OXA_SD")]

out.CoIs[1, c("ESA_mean")] <- out.CoIs[2, c("ESA_mean")]
out.CoIs[1, c("ESA_SD")] <- out.CoIs[2, c("ESA_SD")]

out.CoIs[1, c("Conc.Solids.mug.gMES")] <- out.CoIs[2, c("Conc.Solids.mug.gMES")]
out.CoIs[1, c("Conc.Solids.ug.gMES.SD")] <- out.CoIs[2, c("Conc.Solids.ug.gMES.SD")]

out.CoIs[1, c("ExpMES.Kg")] <- out.CoIs[2, c("ExpMES.Kg")]

# Assign linear approximation of trailing and leading observed values
out.CoIs <- out.CoIs[with(out.CoIs , order(ti)), ]

APPROX = F
if (APPROX) {
  out.CoIs$Conc.mug.L <- na.approx(out.CoIs$Conc.mug.L)
  out.CoIs$Conc.SD <- na.approx(out.CoIs$Conc.SD)
  
  out.CoIs$OXA_mean <- na.approx(out.CoIs$OXA_mean)
  out.CoIs$OXA_SD <- na.approx(out.CoIs$OXA_SD)
  
  out.CoIs$ESA_mean <- na.approx(out.CoIs$ESA_mean)
  out.CoIs$ESA_SD <- na.approx(out.CoIs$ESA_SD)
  
  out.CoIs$Conc.Solids.mug.gMES <- na.approx(out.CoIs$Conc.Solids.mug.gMES)
  out.CoIs$Conc.Solids.ug.gMES.SD <- na.approx(out.CoIs$Conc.Solids.ug.gMES.SD)
  
  out.CoIs$ExpMES.Kg <- na.approx(out.CoIs$ExpMES.Kg)
}
#val = out.CoIs$Volume.m3[nrow(out.CoIs)]
#if (is.na(val)){
#  out.CoIs = out.CoIs[1:nrow(out.CoIs)-1, ]  
#}




```

### Conversion of concentration to loadings (mass)

Exported mass observed at the outlet $M$ for sample $s$ is computed as,   

$$M_{s} = C_{s} \cdot V_{s}$$
and,

$$ V_s = \int^{\Delta t}_t Q(t) dt $$
where $dt$ should be 2 min and $\Delta t$ the length of the subsample.

Doubts with different expression:

$$ V_{s} = \sum^{J}_{j=1} \int^{2}_0 Q(t) dt$$
where $C$ the concentration [$\mu g/L$] of sub-sample $s$, $V$ is volume [$m^3$], $J$ is the array length of the 2-min interval composite sub-sample and $Q$ is discharge.

```{r}
# Dissolved - [mg] S-metolachlor exported per sub-week
# Conc. [mu.g s-meto/L H20] * Vol[m3] * [10^3 L/m^3] * [1 mg/10^3 mu.g]
out.CoIs$DissSmeto.mg = out.CoIs$Conc.mug.L*out.CoIs$Volume.m3
out.CoIs$DissSmeto.mg.SD = out.CoIs$Conc.SD*out.CoIs$Volume.m3
out.CoIs$DissSmeto.g = out.CoIs$DissSmeto.mg/10^3
out.CoIs$DissSmeto.g.SD = out.CoIs$DissSmeto.mg.SD/10^3

out.CoIs$DissOXA.mg = out.CoIs$OXA_mean*out.CoIs$Volume.m3
out.CoIs$DissOXA.mg.SD = out.CoIs$OXA_SD*out.CoIs$Volume.m3
out.CoIs$DissOXA.g = out.CoIs$DissOXA.mg/10^3
out.CoIs$DissOXA.g.SD = out.CoIs$DissOXA.mg.SD/10^3

out.CoIs$DissESA.mg = out.CoIs$ESA_mean*out.CoIs$Volume.m3 
out.CoIs$DissESA.mg.SD = out.CoIs$ESA_SD*out.CoIs$Volume.m3 
out.CoIs$DissESA.g = out.CoIs$DissESA.mg/10^3
out.CoIs$DissESA.g.SD = out.CoIs$DissESA.mg.SD/10^3

# Solids - [mg] S-metolachlor in solids exported per sub-week 
# Conc. [mu.g s-meto / g MES] * Kg MES * [10^3 g/Kg] * [1 mg/10^3 mu.g]
out.CoIs$FiltSmeto.mg = out.CoIs$Conc.Solids.mug.gMES*out.CoIs$ExpMES.Kg 
out.CoIs$FiltSmeto.mg.SD = out.CoIs$Conc.Solids.ug.gMES.SD*out.CoIs$ExpMES.Kg 
out.CoIs$FiltSmeto.g = out.CoIs$FiltSmeto.mg/10^3
out.CoIs$FiltSmeto.g.SD  = out.CoIs$FiltSmeto.mg.SD/10^3
  
# Total SM
out.CoIs$TotSMout.mg = out.CoIs$DissSmeto.mg + out.CoIs$FiltSmeto.mg
out.CoIs$TotSMout.mg.SD = sqrt(((out.CoIs$DissSmeto.mg.SD)^2 + (out.CoIs$FiltSmeto.mg.SD)^2)/2)
out.CoIs$TotSMout.g = out.CoIs$TotSMout.mg/10^3
out.CoIs$TotSMout.g.SD = out.CoIs$TotSMout.mg.SD/10^3

# Distribution dissolved vs suspended solids
out.CoIs$FracDiss = out.CoIs$DissSmeto.mg/out.CoIs$TotSMout.mg
out.CoIs$FracFilt = out.CoIs$FiltSmeto.mg/out.CoIs$TotSMout.mg

#out.CoIs$DissSmeto.g = ifelse(is.na(out.CoIs$DissSmeto.g), 0.0, out.CoIs$DissSmeto.g)
#out.CoIs$FiltSmeto.g = ifelse(is.na(out.CoIs$FiltSmeto.g), 0.0, out.CoIs$FiltSmeto.g)
#out.CoIs$TotSMout.g = out.CoIs$DissSmeto.g + out.CoIs$FiltSmeto.g

write.csv2(out.CoIs, 
           'Data/MonitoringScope_R.csv', row.names = F)

```


## Molar mass equivalent exports

Mass equivalent loads are calculated such that:

$$
MEQ_{SMET} = 
  SMET_{out} + OXA_{out} * (\frac{mw_{SMET}}{mw_{MOXA}}) +
  ESA_{out} * (\frac{mw_{SMET}}{mw_{MESA}})
$$


```{r}
# Need to update this :
# out.CoIs$TotSMout.g.SD = out.CoIs$DissSmeto.g.SD

mw.SM <- 283.796 # g/mol
mw.MOXA <- 279.33 # g/ml
mw.MESA <- 329.1 # g/mol
out.CoIs$MELsm.g <- 
  out.CoIs$TotSMout.g + 
  out.CoIs$DissOXA.g * (mw.SM/mw.MOXA) +
  out.CoIs$DissESA.g * (mw.SM/mw.MESA)

# How to sum a standard deviation
# http://stats.stackexchange.com/questions/25848/how-to-sum-a-standard-deviation
out.CoIs$MELsm.g.SD <- 
  sqrt((out.CoIs$TotSMout.g.SD^2 +
     (out.CoIs$DissOXA.g.SD * (mw.SM/mw.MOXA))^2 +
     (out.CoIs$DissESA.g.SD * (mw.SM/mw.MESA))^2)/3)

# Cumulative OUT
out.CoIs$CumOutDiss.g = cumsum(out.CoIs$DissSmeto.g)
out.CoIs$CumOutFilt.g = cumsum(out.CoIs$FiltSmeto.g)
out.CoIs$CumOutSmeto.g = out.CoIs$CumOutDiss.g + out.CoIs$CumOutFilt.g
out.CoIs$CumOutMELsm.g = cumsum(out.CoIs$MELsm.g)
```

## Hydrochemistry

```{r}
# Hydrochemistrty
# out.CoIs = merge(out.CoIs, hydroChem, by= "WeekSubWeek", all = F)
```



## Application dates and masses

- **IMPORTANT: This is reviewed and final in Open Rayleigh - Revised (Book 09.3)**

Add the application dates and merge the total mass to the nearest discharge event

The 4 application dates were:

- 2016-03-20 (Friess, Beet) and 2016-03-25 (Matthis, Beet)
- 2016-04-13 and 2016-04-14 (Kopp and Burger, Beet)
- 2016-05-25 (Schmidt, Talweg, Corn)
- 2016-06-04 (Assumed Speich and Mahler, Corn not on transect, Except Speich N1)

So the total applied mass mass is merged at the nearest sampling time marker available : 

```{r}
ti = c(as.POSIXct('2016-03-25 00:04:00' , tz="EST"),
#       as.POSIXct('2016-04-05 15:08:00' , tz="EST"),
       as.POSIXct('2016-04-14 13:52:00' , tz="EST"),
       as.POSIXct('2016-05-29 12:10:00' , tz="EST"),
       # as.POSIXct('2016-05-24 12:00:00' , tz="EST"),
       as.POSIXct('2016-06-04 15:32:00' , tz="EST"))

# Appl.Mass.g = c(17319.059, 4744.571, 1891.742, 6826.825) # With Friess applying MG's doses for Beet 
# Appl.Mass.g = c(33242.550, 4744.571, 1891.742, 6826.825) # With Friess applying DG's doses instead of MG's
# Appl.Mass.g = c(31670.073, 4744.571, 1803.066, 6506.818) # With Friess applying MG's doses for Corn 
Appl.Mass.g = c(31670.073, 12316.197, 1803.066, 6506.818) # With Kopp applying MG's doses for Corn, not Beet 

# OT: Only plot areas crossed by Transect
### With Kopp applying MG's doses for Corn, not Beet 
# Appl.Mass.g.OT = c(24477.491, 12249.068, 1803.066, 4454.233) 
# Appl.Mass.g.OT = c(14648.725, 12249.068, 1803.066, 6307.544) # Friess's, S-15 on transect
# Friess & Kopp applying MG's doses for Corn, not Beet
Appl.Mass.g.OT = c(24477.491, 12249.068, 1803.066, 6307.544) 
```

## Temperatures and soil moisture after application

The mean and ranges of air temperatures 120 hr. (5 days) after each application were:

- 1st Application: 8.3 (6.7 - 9.2)
- 2nd Application: 9.6 (7.4 - 11.2)
- 3rd Application: 14.4 (10.9 - 17.4)
- 4th Application: 16.9 (14.9 - 19.3)
```{r}

temp_1st = c(6.70, 9.10, 8.40, 8.20, 9.20)
temp_2nd = c(11.00, 11.20, 10.00, 7.40, 8.20)
temp_3rd = c(17.30, 11.10, 10.90, 13.70, 17.40)
temp_4th = c(19.30, 18.70, 17.00, 14.90, 14.90)

temp_list = list(temp_1st, temp_2nd, temp_3rd, temp_4th)

temp_all = Reduce(c,temp_list)

# Mean
mean(temp_all)

# Std. Dev:
sd(temp_all)
```



Moisture conditions during the same periods where:

```{r}
theta_1st = c(27.40, 30.17, 29.66)
theta_2nd = c(22.43, 23.90, 22.33, 25.90, 30.02, 25.46)
theta_3rd = c(25.30, 29.33, 26.85, 14.37, 17.82, 21.36)
theta_4th = c(14.37, 17.82, 21.36, 27.94, 30.38, 26.87)

theta_list = list(theta_1st, theta_2nd, theta_3rd, theta_4th)

theta_all = Reduce(c,theta_list)

# Mean
mean(theta_all)

# Std. Dev:
sd(theta_all)

min(theta_all)
max(theta_all)
```

```{r}
# 1st Application (Composite 1): 
mean(theta_1st)
min(theta_1st)
max(theta_1st)

# 2nd Application (Composites 2 & 3):
mean(theta_1st)
min(theta_1st)
max(theta_1st)


# 3rd Application (Composites 9 & 10):
mean(theta_1st)
min(theta_1st)
max(theta_1st)

# 4th Application (Composites 10 & 11):
mean(theta_4th)
min(theta_4th)
max(theta_4th)
```

## Initial soil concentrations (Open Rayleigh requirements)

Open system Rayleigh calculations require estimation of cumulative initial concentration ($C(a)_{Tr_0}$) after any number of plot applications $a$ taking place in a composite sample (i.e. Transect ($Tr$)) and given by:

$$C(a)_{Tr_0} = \sum_{a=1} ^{A} \sum_{i=1}^{I} C(a)_{i} \cdot \frac{A_{i}}{A_{Tr}}$$

where $C(a)_i$ is the soil concentation due to application $a$ in plot $i$, $A_i$ is the plot area and $A_{Tr}$ the total plot area associated to transect ($Tr$) (i.e. this is proportional to sampling points along transect, and not extrapolated to areas that the transect did not cross). Note that initial concentrations at each transect will be later extrapolated to the catchment to calculate initial catchment concentrations (bulk), which in turn do take into account the full catchment area.


```{r}
# OT: Only plot areas crossed by Transect

### With Kopp applying MG's doses for Corn, not Beet &
# Matthis applying extra DG's doses for Corn, or using slightly higher MG doses 
# Appl.Mass.g.OT = c(27076.406, 12249.068, 1803.066, 4454.233) 

Appl.Mass.g.N <- c(8429.434, 7810.101, 0, 5346.189)
Appl.Mass.g.N.OT <- c(8429.434, 7810.101, 0, 3293.605) # Friess with DG
# Appl.Mass.g.N.OT <- c(2528.830, 7810.101, 0, 3293.605) # Friess with MG

Appl.Mass.g.T <- c(6903.610, 3073.636, 1803.066, 0)
Appl.Mass.g.T.OT <- c(2727.322, 3006.507, 1803.066, 0) # Friess with DG
# Appl.Mass.g.T.OT <- c(818.196, 3006.507, 1803.066, 0) # Friess with MG

Appl.Mass.g.S <- c(16337.030, 1432.460, 0, 1160.628)
## Options:
# 1
# Appl.Mass.g.S.OT <- c(13320.736, 1432.460, 0, 1160.628)
Appl.Mass.g.S.OT <- c(13320.736, 1432.460, 0, 3016.294) # Friess's S-15 on transect
# Appl.Mass.g.S.OT <- c(11301.698, 1432.460, 0, 3016.294) # Friess's S-15 on transect, Freiss with MG for Beet

# 2 
# Matthis applying DG's doses for Corn, but using MG 
# Appl.Mass.g.S.OT <- c(15919.651, 1432.460, 0, 1160.628)

# Initial soil concentration (needed for Rayleigh calculations later)

# Effective area [m2] refers to plot area touched by a transect, not sub-catchment area.
Narea_eff <- 101721.702
Tarea_eff <- 39247.330
Sarea_eff <- 109903.101 # With S-15 (Friess Corn) on Transect

MGplotConc.Corn <- 19.592 # Assume for Friess, as he grew both Corn and Beet 
MGplotConc.Beet <- 5.878 # ug/g soil for Mercantor Gold
DGplotConc <- 19.607 # Dual Gold
# MGbutDG.Matthis <- 24.490

### Initial concentrations: 

# First applciations
north_first <- 
  # MGplotConc.Beet*(43903.301/Narea_eff) # Friess Area fraction, ug/g
  MGplotConc.Corn*(43903.301/Narea_eff) # Friess Area fraction, ug/g

talweg_first <- 
  # MGplotConc.Beet*(14204.800/Tarea_eff) # Friess
  MGplotConc.Corn*(14204.800/Tarea_eff) # Friess
  # DGplotConc*(14204.800/Tarea_eff) # Friess

south_first <- 
  # MGplotConc.Beet*(15022.6/Sarea_eff)+ # Friess, S-11
  MGplotConc.Corn*(15022.6/Sarea_eff)+ # Friess, S-11
  # DGplotConc*(15022.6/Sarea_eff)+ # Friess, S-11
  # DGplotConc*(15697.6/Sarea_eff)+ # Friess, S-15  # Now or in May??
  # MGplotConc.Beet*(54313.801/Sarea_eff) # Mathis area/area_tot.S
  DGplotConc*(54313.801/Sarea_eff) # Mathis area/area_tot.S
  #MGbutDG.Matthis*(54313.801/Sarea_eff) # Mathis area/area_tot.S
  
# Second applications
north_second <- 
  north_first+
  MGplotConc.Corn*(9452.500/Narea_eff+ # Kopp, N-4
                     13776.500/Narea_eff+ # Kopp, N-7
                     17448.600/Narea_eff) # Kopp, N-8
talweg_second <- 
  talweg_first+
  MGplotConc.Corn*(2965.980/Tarea_eff # Kopp, T-4
                   + 5336.080/Tarea_eff # Kopp, T-7
                   + 7356.830/Tarea_eff) # Kopp, T-8
south_second <- 
  south_first +
  MGplotConc.Beet*(24869.100/Sarea_eff) # Burger

# Third applications
north_third <- north_second

talweg_third <- 
  talweg_second+
  DGplotConc*(9383.640/Tarea_eff) # Schmitt, T-10

south_third <- south_second

# Fourth applications
north_fourth <- 
  north_second+
  # MGplotConc.Corn*(17140.801/Narea_eff) # Speich Corn with MG
  DGplotConc*(17140.801/Narea_eff) # Speich Corn with DG

talweg_fourth <- talweg_third
# south_fourth <- south_second # If Speich's S-70 not in transect
south_fourth <- south_second +
  MGplotConc.Corn*(6040.220/Narea_eff) + # Speich Corn with MG (South Transect)
  DGplotConc*(15697.6/Sarea_eff) # Friess, S-15  # Now or in April??

applics = as.data.frame(ti)
applics$Appl.Mass.g = Appl.Mass.g
applics$Appl.Mass.g.OT = Appl.Mass.g.OT
applics$Appl.Mass.g.N = Appl.Mass.g.N
applics$Appl.Mass.g.T = Appl.Mass.g.T
applics$Appl.Mass.g.S = Appl.Mass.g.S

applics$Appl.Mass.g.N.OT = Appl.Mass.g.N.OT
applics$Appl.Mass.g.T.OT = Appl.Mass.g.T.OT
applics$Appl.Mass.g.S.OT = Appl.Mass.g.S.OT

applics$iniCo.ug.g.N = c(north_first, north_second, north_third, north_fourth)
applics$iniCo.ug.g.T = c(talweg_first, talweg_second, talweg_third, talweg_fourth)
applics$iniCo.ug.g.S = c(south_first, south_second, south_third, south_fourth)

out.CoIs = merge(out.CoIs, applics, by = "ti", all = T)

out.CoIs$Appl.Mass.g <- ifelse(is.na(out.CoIs$Appl.Mass.g), 0.0, out.CoIs$Appl.Mass.g)
out.CoIs$Appl.Mass.g.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.OT), 0.0, out.CoIs$Appl.Mass.g.OT)

out.CoIs$Appl.Mass.g.N <- ifelse(is.na(out.CoIs$Appl.Mass.g.N), 0.0, out.CoIs$Appl.Mass.g.N)
out.CoIs$Appl.Mass.g.T <- ifelse(is.na(out.CoIs$Appl.Mass.g.T), 0.0, out.CoIs$Appl.Mass.g.T)
out.CoIs$Appl.Mass.g.S <- ifelse(is.na(out.CoIs$Appl.Mass.g.S), 0.0, out.CoIs$Appl.Mass.g.S)

out.CoIs$Appl.Mass.g.N.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.N.OT), 0.0, out.CoIs$Appl.Mass.g.N.OT)
out.CoIs$Appl.Mass.g.T.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.T.OT), 0.0, out.CoIs$Appl.Mass.g.T.OT)
out.CoIs$Appl.Mass.g.S.OT <- ifelse(is.na(out.CoIs$Appl.Mass.g.S.OT), 0.0, out.CoIs$Appl.Mass.g.S.OT)

out.CoIs$timeSinceApp <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g'] != 0){
    out.CoIs[i,]['timeSinceApp'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp']
  }
}

out.CoIs$timeSinceApp.N <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.N'] != 0){
    out.CoIs[i,]['timeSinceApp.N'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.N'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.N']
  }
}

out.CoIs$timeSinceApp.T <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.T'] != 0){
    out.CoIs[i,]['timeSinceApp.T'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.T'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.T']
  }
}

out.CoIs$timeSinceApp.S <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.S'] != 0){
    out.CoIs[i,]['timeSinceApp.S'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.S'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.S']
  }
}

# Not in South
out.CoIs$Appl.Mass.g.NoSo <- out.CoIs$Appl.Mass.g
out.CoIs$Appl.Mass.g.NoSo[which(out.CoIs$ti == as.POSIXct('2016-05-23 18:02:00' , tz="EST"))] <- 0
out.CoIs$timeSinceApp.NoSo <- NA
for (i in 1:length(out.CoIs$Duration.Hrs)){
  if (out.CoIs[i, ]['Appl.Mass.g.NoSo'] != 0){
    out.CoIs[i,]['timeSinceApp.NoSo'] = out.CoIs[i, ]['Duration.Hrs']
  } else {
    out.CoIs[i, ]['timeSinceApp.NoSo'] = out.CoIs[i ,]['Duration.Hrs'] + out.CoIs[i-1,]['timeSinceApp.NoSo']
  }
}


out.CoIs$timeSinceApp <- round(out.CoIs$timeSinceApp/24, 1) # Convert to days
out.CoIs$timeSinceApp.NoSo <- round(out.CoIs$timeSinceApp.NoSo/24, 1)
out.CoIs$timeSinceApp.N <- round(out.CoIs$timeSinceApp.N/24, 1) # Convert to days
out.CoIs$timeSinceApp.T <- round(out.CoIs$timeSinceApp.T/24, 1) # Convert to days
out.CoIs$timeSinceApp.S <- round(out.CoIs$timeSinceApp.S/24, 1) # Convert to days

# Cumulative (Continous)
out.CoIs$CumAppMass.g = cumsum(out.CoIs$Appl.Mass.g)
out.CoIs$CumAppMass.g.OT = cumsum(out.CoIs$Appl.Mass.g.OT)
out.CoIs$CumAppMass.g.N = cumsum(out.CoIs$Appl.Mass.g.N)
out.CoIs$CumAppMass.g.T = cumsum(out.CoIs$Appl.Mass.g.T)
out.CoIs$CumAppMass.g.S = cumsum(out.CoIs$Appl.Mass.g.S)
out.CoIs$CumAppMass.g.N.OT = cumsum(out.CoIs$Appl.Mass.g.N.OT)
out.CoIs$CumAppMass.g.T.OT = cumsum(out.CoIs$Appl.Mass.g.T.OT)
out.CoIs$CumAppMass.g.S.OT = cumsum(out.CoIs$Appl.Mass.g.S.OT)

out.CoIs$iniCo.ug.g.N = na.locf(out.CoIs$iniCo.ug.g.N)
out.CoIs$iniCo.ug.g.T = na.locf(out.CoIs$iniCo.ug.g.T)
out.CoIs$iniCo.ug.g.S = na.locf(out.CoIs$iniCo.ug.g.S)


```

## Balance

```{r}
# Balance
out.CoIs$BalMassDisch.g = out.CoIs$CumAppMass.g - out.CoIs$CumOutMELsm.g

# Mass fraction
massOUT = tail(out.CoIs$CumOutSmeto.g, n=1)
MELsmOUT = tail(out.CoIs$CumOutMELsm.g, n=1)

TotAppl = tail(out.CoIs$CumAppMass.g, n=1)

out.CoIs$prctMassOut = (out.CoIs$TotSMout.g / massOUT)
out.CoIs$FracDeltaOut = (out.CoIs$TotSMout.g / massOUT)*out.CoIs$diss.d13C
out.CoIs$FracDeltaOut = ifelse(is.na(out.CoIs$FracDeltaOut), 0.0, out.CoIs$FracDeltaOut)

BulkDeltaOut = sum(out.CoIs$FracDeltaOut)
```



The total mass discharged (up to Week 15) and bulk isotope signature (up to week 11) was:

```{r}
# Cummulative S-metolachlor [g] discharged (before correction)
cat("SM mass sampled: " , as.character(91.10687))

# Cummulative S-metolachlor [g] discharged
cat("SM mass sampled and non-sampled: ",  as.character(massOUT)) 

# Cummulative MEL-sm [g] discharged
cat("MEL-sm [g] sampled and non-sampled: ",  as.character(MELsmOUT)) 

cat("% Mass applied in discahrge [MEL-sm]: ",  (MELsmOUT/TotAppl)*100)

# Bulk isotope signature
BulkDeltaOut
```


## Save files

```{r, message=FALSE}

names(out.CoIs)[names(out.CoIs) == "Event"] <- "Peak"
nrow(out.CoIs)
out.CoIs$Events <- as.factor(c("0-1", "0-2", "0-3",
                         "1-1", "1-2", "1-3", 
                         "2-1", "2-2", "2-3", 
                         "3-1", 
                         "4-1", "4-2", "4-3", "4-4", "4-5",
                         "5-1", 
                         "6-1", "6-2", "6-3",
                         "7-1", 
                         "8-1", "8-2", "8-3",
                         "9-1", "9-2", "9-3", "9-4", "9-5",
                         "10-1", "10-2", "10-3", "10-4", "10-5", 
                         "11-1", 
                         "12-1", "12-2", "12-3",
                         "13-1",
                         "14-1",
                         "15-1", "15-2", "15-3", "15-4", 
                         "16-1", "16-2", 
                         "17-1", "17-2",
                         "18-1", "18-2", "18-3", "18-4",
                         "19-1", "19-1" # Base flow 
                         ))

# Adding a Weeks column for labelling
out.CoIs$WeekSubWeek <- as.character(out.CoIs$WeekSubWeek)
Split <- strsplit(out.CoIs$WeekSubWeek, "-", fixed = TRUE)
out.CoIs$Weeks <- sapply(Split, "[", 1)

Split2 <- strsplit(as.character(out.CoIs$Events), "-", fixed = T)
out.CoIs$Event <- as.factor(sapply(Split2, "[", 1))

out.CoIs$WeekSubWeek <- factor(out.CoIs$WeekSubWeek, levels = unique(out.CoIs$WeekSubWeek))
out.CoIs$Weeks <- factor(out.CoIs$Weeks, levels = unique(out.CoIs$Weeks))

out.CoIs$Events <- factor(out.CoIs$Events, levels = unique(out.CoIs$Events))
out.CoIs$Event <- factor(out.CoIs$Event, levels = unique(out.CoIs$Event))

head(out.CoIs)

write.csv2(out.CoIs, 
           'Data/WeeklyHydroContam_R.csv', row.names = F)
sum(is.na(out.CoIs$maxQ))

# out.CoIs = read.csv2("Data/WeeklyHydroContam_R.csv")
# out.CoIs$ti = as.POSIXct(out.CoIs$ti, "%Y-%m-%d %H:%M", tz = "EST")

```

