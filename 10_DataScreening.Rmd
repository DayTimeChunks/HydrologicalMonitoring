---
title: "Data Screening"
author: "PAZ"
date: "06/04/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)
Sys.setlocale("LC_ALL", "English")
```

# Introduction

This Data Screenining notebook follows the GUide to STatistical Analysis in Microbial Ecology (GUSTA ME). The purpose is to inspect the variables that we'll be using to test for hypotheses later on, and check whether they follow typical assumptions made in parametric tests such as normality, freedom from heteroskedasticity (difference in variability btw. two+ variables) and outliers. 

Reference:

https://sites.google.com/site/mb3gustame/home
Buttigieg PL, Ramette A (2014) A Guide to Statistical Analysis in Microbial Ecology: a community-focused, living review of multivariate data analyses. FEMS Microbiol Ecol. 90: 543-550.

# Packages

```{r, warning=FALSE,}
library(sm)
library(vioplot)

library(dplyr)
library(ggplot2)
library("ggrepel")
```


# Missing values

1. Missing chemical and isotope data due to machine failure or automatic sampling servicing program.

These have been considered to be Values Missing Completely at Random (MCAR) as they are associated to the end of the automatic sampler's capacity for a certain number of events where servicing was inadequate for the discharge amounts seen during a sampling week. Here the values' missingess is not related to any other value in the data set. 

2. Isotope data for both soil and water samples due to concentration value being below the limit of detection.

These values must be considered to be Missing at Random (MAR) as the missing value has no relation to the value that 'should' be there, but does depend on other variables in the data set. Thus, other variables must be taken into account for MAR data to be considered random (i.e. missing data is "conditioned by" other data in the data set). 

# Import soils 

Convert to single time observation for merging with water observation.


```{r}
# Soils
soils = read.csv2("Data/MassBalance_R.csv", 
                       na.strings=c('#DIV/0!', '', 'NA'), header = TRUE)
colnames(soils)[colnames(soils) == "ti"] <- "Date.ti"
soils$Date.ti <- as.POSIXct(strptime(soils$Date.ti, 
                                          "%Y-%m-%d %H:%M", tz="EST")) # csv typos, option 1
sum(is.na(soils$Date.ti)) == 0

dropSoil <- c("WeekSubWeek", "Event", 
              "B.diss", "B.filt", "CumOutDiss.g", "CumOutFilt.g", "CumOutAppMass.g",  "CumOutMELsm.g", 
              "CumAppMass.g",
              "ID.N", "ID.T",  "Area.N", "Area.T", "Area.S",
              "comp.d13C.SE.North", "comp.d13C.SE.Talweg", "comp.d13C.SE.South", 
              "f.max.comp", "f.mean.comp", "f.min.comp", "ngC.SD","ngC.SE", "N_compsoil", "N_ngC")
soils <- soils[ , !(names(soils) %in% dropSoil)]


# Quasi-Molten SOILS
soilGroups = read.csv2("Data/WeeklySoils_Rng.csv", 
                       na.strings=c('#DIV/0!', '', 'NA'), header = TRUE)
soilGroups$Date.ti <- as.POSIXct(strptime(soilGroups$Date.ti, 
                                          "%Y-%m-%d %H:%M", tz="EST")) # csv typos, option 1
sum(is.na(soilGroups$Date.ti)) == 0

str(soils)



ggplot(soilGroups, aes(x=Conc.mug.g.dry.soil, y=comp.d13C))+
  geom_point(aes(group = Transect, colour = Wnum, shape = Transect))+
  geom_text_repel(aes(label=Wnum),
                 arrow = arrow(length = unit(0.005, 'npc'), type = "closed"),
                 force = 1, 
                 point.padding = unit(1.0, 'lines'), 
                 max.iter = 2e3,
                 nudge_x = .2) #+
  #stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  #stat_smooth(method = "lm", formula = y~x, se=F) 

```

Soils to confirm in IRMS:

North: 13, 12, 10, 9, 11, 7
Talweg: 13, 10, 9, 8, 7
South: 13

No isotopes:
Talweg: 1, 15
North: 1, 5, 6, 15
South: 15

Repeat:



Import water

```{r}
waters = read.csv2("Data/WeeklyHydroContam_R.csv")
waters$ti <- as.POSIXct(strptime(waters$ti, "%Y-%m-%d %H:%M", tz="EST"))
colnames(waters)[colnames(waters) == "ti"] <- "Date.ti"
waters$Events <- factor(waters$Events, levels = unique(waters$Events))
waters$Event <- factor(waters$Event, levels = unique(waters$Event))

dropWater <- c("N.x", "N.y", 
               "Markers" , "TimeDiff", 
               "se.d13C", "MES.mg.L", "MES.sd", "MO.mg.L", "filt.se.d13C", "f.diss", "f.filt",
               "Appl.Mass.g", 
               "DissSmeto.mg", "DissSmeto.mg.SD", 
               "DissOXA.mg", "DissOXA.mg.SD", 
               "DissESA.mg", "DissESA.mg.SD",
               "FiltSmeto.mg", "DissSmeto.mg.SD", 
               "TotSMout.mg", "TotSMout.mg.SD",
               "FracDiss", "FracFilt")
waters <- waters[ , !(names(waters) %in% dropWater)]


# Date conversion correct: 
sum(is.na(waters$Date.ti)) == 0
str(waters)
```

# Merge Soil and Water data frames

```{r}
WaterSoils <- merge(waters, soils, by = "Date.ti", all = F)
str(WaterSoils)
```

# Outliers

```{r}
# Test function
g_param = 1.5
# g_param = 2.2  #  (Hoaglin et al.,1986; Hoaglin & Iglewicz, 1987) 
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - g_param * IQR(x) | x > quantile(x, 0.75) + g_param * IQR(x))
}


```


## Soil concentrations

Correlation will be made after variable transformation. Options tested:

a) Z-scoring transformation by translation and expansion is done to create unit-free variables with means of zero and standard deviations of one. Standardised values differ from one another in units of standard deviation. The mean of each variable is subtracted from the original values and the difference divided by the variable's standard deviation and is given by:

$$ z_i = \frac{y_i - \bar{y}}{s_y} $$

Z-scoring did not change correlation results, nor outlier reduction.

b) Scaling by expansion where all values are divided by the maximum observation.

### Outliers before transformation

```{r}

# Concentrations
soilGroups %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(Conc.mug.g.dry.soil), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = Conc.mug.g.dry.soil)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)

```

### Outliers after transformation

```{r}
soilGroups <- soilGroups %>%
  group_by(Transect) %>%
  mutate(z_conc = (Conc.mug.g.dry.soil-mean(Conc.mug.g.dry.soil))/sd(Conc.mug.g.dry.soil))


soilGroups %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(z_conc), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = z_conc)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)
```

## Soil Isotopes

```{r}
# Isotopes

temp <- na.omit(soilGroups)

temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(comp.d13C), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = comp.d13C)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)


```

Looks like 7 potential outliers in concentrations and 1 for isotopes. Removing NA's for isotopes and re-computing outliers, reduces the number of outliers to 2 in concentrations and 1 for isotopes. 

```{r}
temp <- temp %>%
  group_by(Transect) %>%
  mutate(z_d13C = (comp.d13C-mean(comp.d13C))/sd(comp.d13C))

temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(z_d13C), as.character(ID), NA)) %>%
  ggplot(., aes(x = factor(Transect), y = z_d13C)) +
    geom_boxplot() +
    geom_text(aes(label = outlier), na.rm = TRUE, hjust = -0.3)

```


## Correlation tests

```{r}
temp <- temp %>%
  group_by(Transect) %>%
  mutate(outlier = ifelse(is_outlier(comp.d13C), 
                          as.character(ID), ifelse(is_outlier(Conc.mug.g.dry.soil), as.character(ID), NA)))

temp.filtered <- temp[is.na(temp$outlier ) , ]
cor.test(temp.filtered$comp.d13C, temp.filtered$Conc.mug.g.dry.soil)


## With outliers
# Log of concentrations -> No change
# cor.test(soilGroups$comp.d13C, log(soilGroups$Conc.mug.g.dry.soil), method = "spearman")
cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil, method = "spearman")

## Z-scoring
cor.test(temp$z_conc, temp$z_d13C)
```



```{r}
cor.test(soilGroups$comp.d13C, soilGroups$Conc.mug.g.dry.soil)
```

# Distribution of z values (same as non-transformed)

```{r}
# plot densities 
#sm.density.compare(temp$z_conc, temp$Transect, xlab=expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)})))
sm.density.compare(temp$z_conc, temp$Transect, xlab=expression(paste("Conc. S-Meto.  Z-values")))
title(main="Catchment Soil - Concentrations")
legend("topright", levels( soilGroups$Transect), fill=2+(0:nlevels(soilGroups$Transect)))
       
#vioplot(soilGroups$Conc.mug.g.dry.soil,  names = "Catchment")
#title(expression(paste("Conc. S-Meto.  ", {({mu}*g / g.soil.dry)})))
```

## Soil Isotopes

```{r}
#vioplot(na.omit(soilGroups$comp.d13C),  names = "Catchment")
#title(expression(paste({delta}^"13","C", ' (\u2030)')))
```

```{r}

temp <- na.omit(soilGroups)
sm.density.compare(temp$comp.d13C, temp$Transect, 
                   xlab=expression(paste({delta}^"13","C", ' (\u2030)')))
title(main="Catchment Soil - Isotope Distribution")
legend("topright", levels( soilGroups$Transect), fill=2+(0:nlevels(soilGroups$Transect)))
```


```{r}

```


